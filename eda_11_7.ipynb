{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import gc\n",
    "import itertools\n",
    "import tqdm\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import scipy.stats as ss\n",
    "from numba import jit\n",
    "\n",
    "if os.name=='nt':\n",
    "    try:\n",
    "        mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin'\n",
    "        os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_features(df, lags, merge_cols, shift_cols, fillna_value=None):\n",
    "    '''create lag features of col'''\n",
    "    cols = copy.copy(merge_cols)\n",
    "    cols.extend(shift_cols)\n",
    "    tmp = df.loc[:, cols]\n",
    "    for i in lags:\n",
    "        shifted = tmp.copy()\n",
    "        shifted_cols = shifted.columns.tolist()\n",
    "        shifted_cols = [c+'_lag_'+str(i) if c in shift_cols else c \n",
    "                        for c in shifted_cols]\n",
    "        shifted.columns = shifted_cols\n",
    "        shifted['month'] += i\n",
    "        shifted.drop_duplicates(inplace=True)\n",
    "        df = pd.merge(df, shifted, on=merge_cols, how='left')\n",
    "    if fillna_value is not None:\n",
    "        df.fillna(fillna_value, inplace=True)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_rmse(preds, dtrain):\n",
    "    y_test = np.array(dtrain.get_label())\n",
    "    preds = np.array(preds)\n",
    "    y_test = np.maximum(np.minimum(y_test, 20), 0)\n",
    "    preds = np.maximum(np.minimum(preds, 20), 0)\n",
    "    #preds = np.array(list(map(lambda x: min(20, max(x, 0)), list(preds))))\n",
    "    #y_test = np.array(list(map(lambda x: min(20, max(x, 0)), list(y_test))))\n",
    "    rmse = np.sqrt(mean_squared_error(preds,y_test))\n",
    "    return 'clip-rmse', rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(x_train, y_train, param, n_repetition, n_split, n_tree, verbose, random_state):\n",
    "    '''Repeated CV'''\n",
    "    \n",
    "    cv_results = {}\n",
    "    clf = {}\n",
    "    running_time = {}\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    for m in range(n_repetition):\n",
    "        # Train and valuation sets split\n",
    "        skf = StratifiedKFold(n_splits=n_split, random_state=np.random.randint(10**6), shuffle=True)\n",
    "\n",
    "        for n, (train_index, val_index) in enumerate(skf.split(x_train, y_train)):\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Construct DMatrix\n",
    "            dtrain = xgb.DMatrix(x_train.iloc[train_index], label=y_train.iloc[train_index])\n",
    "            dval = xgb.DMatrix(x_train.iloc[val_index], label=y_train.iloc[val_index])\n",
    "\n",
    "            # Placeholder for evals_results\n",
    "            cv_results[m, n] = {}\n",
    "\n",
    "            param['seed'] = np.random.randint(10**6)\n",
    "            clf[m, n] = xgb.train(param, dtrain,num_boost_round=n_tree, \n",
    "                                  evals=[(dtrain, 'train'), (dval, 'val')], \n",
    "                                  feval=clip_rmse, maximize=False, early_stopping_rounds=None, \n",
    "                                  evals_result=cv_results[m, n], verbose_eval=verbose)\n",
    "\n",
    "            running_time[m, n] = time.time() - start_time\n",
    "\n",
    "            print('Repeat {}, split {}, val score = {:.3f}, running time = {:.3f} min.'.format(m, n, \n",
    "                cv_results[m, n]['val']['clip-rmse'][-1], running_time[m, n]/60))\n",
    "\n",
    "    cv_results_final = {}\n",
    "    for m in range(n_repetition):\n",
    "        for n in range(n_split):\n",
    "            cv_results_final['train', m, n] = cv_results[m, n]['train']['clip-rmse']\n",
    "            cv_results_final['val', m, n] = cv_results[m, n]['val']['clip-rmse']\n",
    "\n",
    "    df = pd.DataFrame(cv_results_final)\n",
    "    df.index.name = 'iteration'\n",
    "    df.columns.names = ['dataset', 'repetition', 'cv_split']\n",
    "\n",
    "    print('Val mean = {:.3f}, std = {:.3f}'.format(df['val'].iloc[-1].mean(), df['val'].iloc[-1].std()))\n",
    "    \n",
    "    return df, clf, running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_combination(x, feature_list, function_dict, column_name, merge=False):\n",
    "    '''Combination of new features'''\n",
    "    tmp = x.groupby(feature_list).agg(function_dict)\n",
    "    tmp.columns = column_name\n",
    "    if merge:\n",
    "        x = x.merge(tmp, on=feature_list, how='left')\n",
    "        return x, tmp\n",
    "    else:\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('all/sales_train.csv.gz')\n",
    "test = pd.read_csv('all/test.csv.gz')\n",
    "shop = pd.read_csv('all/shops-translated.csv')\n",
    "item = pd.read_csv('all/item_category.csv')\n",
    "\n",
    "test.set_index('ID', inplace=True)\n",
    "item.drop(['item_name_translated'], axis=1, inplace=True)\n",
    "shop.drop(['Name'], axis=1, inplace=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "item['item_cat1'] = le.fit_transform(item['item_cat1'].astype(str))\n",
    "item['item_cat2'] = le.fit_transform(item['item_cat2'].astype(str))\n",
    "shop['City'] = le.fit_transform(shop['City'])\n",
    "shop['Type'] = le.fit_transform(shop['Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.item_price<100000]\n",
    "train = train[train.item_cnt_day<1001]\n",
    "median = train[(train.shop_id==32)&(train.item_id==2973)&(train.date_block_num==4)&(train.item_price>0)].item_price.median()\n",
    "train.loc[train.item_price<0, 'item_price'] = median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix shop names and ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "train.loc[train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monthly sales for all the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(train.groupby(['date_block_num', 'shop_id', 'item_id'])['item_cnt_day'].sum())\n",
    "\n",
    "x.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set only contains sold samples, need to extend to all samples.\n",
    "\n",
    "There are two ways of extending:\n",
    "1. overall product between elements in (month, shop_id, item_id)\n",
    "2. in each month, the product between elements in (shop_id, item_id)\n",
    "\n",
    "The first one increases the number of rows by 23.5 times, the second one 6 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall product count is 42260028, sample count is 1609123, ratio is 26.263\n",
      "monthly product count sum is 10913804, monthly sample count is 1609123, ratio is 6.782\n"
     ]
    }
   ],
   "source": [
    "shop_count = {}\n",
    "item_count = {}\n",
    "product_count = {}\n",
    "sample_count = {}\n",
    "ratio = {}\n",
    "\n",
    "for n in x.date_block_num.unique():\n",
    "    shop_count[n] = len(x.loc[x.date_block_num==n, 'shop_id'].unique())\n",
    "    item_count[n] = len(x.loc[x.date_block_num==n, 'item_id'].unique())\n",
    "    sample_count[n] = len(x.loc[x.date_block_num==n, :])\n",
    "    product_count[n] = shop_count[n]*item_count[n]\n",
    "    ratio[n] = product_count[n]/sample_count[n]\n",
    "#     print('product count is {}, sample count is {}, ratio is {:.3f}'.format(product_count[n], \n",
    "#                                                                             sample_count[n], \n",
    "#                                                                             product_count[n]/sample_count[n]))\n",
    "    \n",
    "print('overall product count is {}, sample count is {}, ratio is {:.3f}'.format(\n",
    "    len(x.shop_id.unique())*len(x.item_id.unique())*34, \n",
    "    x.shape[0], 34*len(x.shop_id.unique())*len(x.item_id.unique())/x.shape[0]))\n",
    "print('monthly product count sum is {}, monthly sample count is {}, ratio is {:.3f}'.format(\n",
    "    sum(product_count.values()), sum(sample_count.values()), sum(product_count.values())/sum(sample_count.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the first extending method\n",
    "\n",
    "It requires huge RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    month = np.arange(0, 34)\n",
    "    shop_list = train.shop_id.unique().tolist()\n",
    "    item_list = train.item_id.unique().tolist()\n",
    "    n_rows = len(month)*len(shop_list)*len(item_list)\n",
    "\n",
    "    idx = pd.MultiIndex.from_product([month, shop_list, item_list], names=['date_block_num', 'shop_id', 'item_id'])\n",
    "\n",
    "    x2 = pd.DataFrame(np.zeros((n_rows,2)), index=idx)\n",
    "    x2.reset_index(inplace=True, drop=False)\n",
    "    x2.drop([0, 1], axis=1, inplace=True)\n",
    "\n",
    "    x = x2.merge(x, on=['date_block_num', 'shop_id', 'item_id'], how='outer').fillna(0.0)\n",
    "    test['date_block_num'] = 34\n",
    "    x = pd.concat((x, test), sort=False).fillna(0.0)\n",
    "\n",
    "    del x2\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the second method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for n in range(34):\n",
    "    shop_list = x.loc[x.date_block_num==n, 'shop_id'].unique()\n",
    "    item_list = x.loc[x.date_block_num==n, 'item_id'].unique()\n",
    "    idx = pd.MultiIndex.from_product([[n], shop_list, item_list], names=['date_block_num', 'shop_id', 'item_id'])\n",
    "    df_tmp = pd.DataFrame(np.zeros((len(idx),2)), index=idx)\n",
    "    tmp.append(df_tmp)\n",
    "tmp = pd.concat(tmp, sort=False)\n",
    "tmp.reset_index(inplace=True, drop=False)\n",
    "tmp.drop([0, 1], axis=1, inplace=True)\n",
    "x = tmp.merge(x, on=['date_block_num', 'shop_id', 'item_id'], how='outer').fillna(0.0)\n",
    "test['date_block_num'] = 34\n",
    "x = pd.concat((x, test), sort=False).fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add shop/item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.merge(x, shop, on='shop_id', how='left')\n",
    "x = pd.merge(x, item, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns = ['month', 'shop_id', 'item_id', 'sales_month', \n",
    "             'City', 'Type', 'item_cat1', 'item_cat2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change column types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x['City'] = x['City'].astype(np.int8)\n",
    "x['Type'] = x['Type'].astype(np.int8)\n",
    "x['item_cat1'] = x['item_cat1'].astype(np.int8)\n",
    "x['item_cat2'] = x['item_cat2'].astype(np.int8)\n",
    "x['sales_month'] = x['sales_month'].astype(np.float16)\n",
    "x['month'] = x['month'].astype(np.int8)\n",
    "x['shop_id'] = x['shop_id'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lag_features(x, [1, 2, 3, 6, 12], \n",
    "                 ['month', 'shop_id', 'item_id'], \n",
    "                 ['sales_month'], fillna_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = x.groupby('month').agg({'sales_month': ['mean']})\n",
    "group.columns = ['sales_mean_month']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=['month'], how='left')\n",
    "x['sales_mean_month'] = x['sales_mean_month'].astype(np.float16)\n",
    "x = lag_features(x, [1], ['month'], ['sales_mean_month'], fillna_value=0.0)\n",
    "x.drop(['sales_mean_month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_item`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_item'\n",
    "group = x.groupby(['month', 'item_id']).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=['month', 'item_id'], how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1, 2, 3, 6, 12], \n",
    "                 ['month', 'item_id'], \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_shop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_shop'\n",
    "merge_cols = ['month', 'shop_id']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1, 2, 3, 6, 12], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_cat1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_cat1'\n",
    "merge_cols = ['month', 'item_cat1']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_shop_cat1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_shop_cat1'\n",
    "merge_cols = ['month', 'shop_id', 'item_cat1']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_shop_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_shop_type'\n",
    "merge_cols = ['month', 'shop_id', 'Type']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_shop_cat2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_shop_cat2'\n",
    "merge_cols = ['month', 'shop_id', 'item_cat2']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_city`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_city'\n",
    "merge_cols = ['month', 'City']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_item_city`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_item_city'\n",
    "merge_cols = ['month', 'item_id', 'City']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_cat2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_cat2'\n",
    "merge_cols = ['month', 'item_cat2']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_cat1_cat2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_cat1_cat2'\n",
    "merge_cols = ['month', 'item_cat1', 'item_cat2']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1, 2, 3, 6], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average price of each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = train.groupby('item_id').agg({'item_price': np.mean})\n",
    "group.columns = ['price_mean_item']\n",
    "x = pd.merge(x, group, on=['item_id'], how='left')\n",
    "x['price_mean_item'] = x['price_mean_item'].astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average price of each item in each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = train.groupby(['date_block_num', 'item_id']).agg({'item_price': np.mean})\n",
    "group.reset_index(inplace=True)\n",
    "group.columns = ['month', 'item_id', 'price_mean_month_item']\n",
    "x = pd.merge(x, group, on=['month', 'item_id'], how='left')\n",
    "x['price_mean_month_item'] = x['price_mean_month_item'].astype(np.float16)\n",
    "\n",
    "lags = [1, 2, 3, 4, 5, 6]\n",
    "x = lag_features(x, lags, merge_cols=['month', 'item_id'], shift_cols=['price_mean_month_item'])\n",
    "\n",
    "# delta price is the difference between price in lag month and mean price over all periods\n",
    "for i in lags:\n",
    "    x['delta_price_mean_month_item_lag_'+str(i)] = \\\n",
    "        (x['price_mean_month_item_lag_'+str(i)] - x['price_mean_item']) / x['price_mean_item']\n",
    "\n",
    "x['price_mean_month_item_diff'] = (x['price_mean_month_item'] - x['price_mean_month_item_lag_1']) / x['price_mean_month_item']\n",
    "x['price_mean_month_item_diff'] = x['price_mean_month_item_diff'].astype(np.float16)\n",
    "x = lag_features(x, lags, merge_cols=['month', 'item_id'], shift_cols=['price_mean_month_item_diff'])\n",
    "\n",
    "x.drop(['price_mean_month_item', 'price_mean_month_item_diff'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last month shop revenue trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['revenue'] = train['item_cnt_day']*train['item_price']\n",
    "group = train.groupby(['date_block_num', 'shop_id']).agg({'revenue': np.sum})\n",
    "\n",
    "group.reset_index(inplace=True)\n",
    "group.columns = ['month', 'shop_id', 'rev_sum_month_shop']\n",
    "\n",
    "x = pd.merge(x, group, on=['month', 'shop_id'], how='left')\n",
    "x['rev_sum_month_shop'] = x['rev_sum_month_shop'].astype(np.float32)\n",
    "\n",
    "group = train.groupby(['shop_id']).agg({'revenue': lambda x: np.sum(x)/34})\n",
    "group.reset_index(inplace=True)\n",
    "group.columns = ['shop_id', 'rev_sum_month_shop_mean_month']\n",
    "\n",
    "x = pd.merge(x, group, on=['shop_id'], how='left')\n",
    "x['delta_rev'] = (x['rev_sum_month_shop'] - x['rev_sum_month_shop_mean_month']) / x['rev_sum_month_shop_mean_month']\n",
    "x = lag_features(x, [1], merge_cols=['month', 'shop_id'], shift_cols=['delta_rev'])\n",
    "x.drop(['rev_sum_month_shop', 'delta_rev'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Month and days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['month2'] = x['month'] % 12\n",
    "x['days_in_month'] = x['month2'].map(pd.Series([31,28,31,30,31,30,31,31,30,31,30,31]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance to the last sold month for (month, shop, item) pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35285f4070014749975ee188c16533bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=35), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = x.pivot_table(index=['shop_id', 'item_id'], \n",
    "                    columns=['month'], \n",
    "                    values=['sales_month']).fillna(0.0)\n",
    "\n",
    "tmp = tmp>0.0\n",
    "for n in tqdm.tqdm_notebook(range(tmp.shape[1])):\n",
    "    tmp.iloc[:, n] = tmp.iloc[:, n].map({False: -1, True: n})\n",
    "tmp = tmp.shift(axis=1).fillna(-1.0).cummax(axis=1)\n",
    "tmp = np.arange(0, 35)-tmp.replace(-1.0, -np.inf)\n",
    "tmp.replace(np.inf, -1, inplace=True)\n",
    "tmp = tmp.stack()\n",
    "tmp.columns = ['shop_item_to_last_sold_month']\n",
    "tmp.reset_index(inplace=True)\n",
    "tmp = tmp[['month', 'shop_id', 'item_id', 'shop_item_to_last_sold_month']]\n",
    "\n",
    "x = pd.merge(x, tmp, on=['month', 'shop_id', 'item_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance to the last sold month for (month, item) pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35540ff552a4510b260e4ec15db3b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=35), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = x.pivot_table(index=['item_id'], \n",
    "                    columns=['month'], \n",
    "                    values=['sales_month']).fillna(0.0)\n",
    "tmp = tmp>0.0\n",
    "for n in tqdm.tqdm_notebook(range(tmp.shape[1])):\n",
    "    tmp.iloc[:, n] = tmp.iloc[:, n].map({False: -1, True: n})\n",
    "tmp = tmp.shift(axis=1).fillna(-1.0).cummax(axis=1)\n",
    "tmp = np.arange(0, 35)-tmp.replace(-1.0, -np.inf)\n",
    "tmp.replace(np.inf, -1, inplace=True)\n",
    "tmp = tmp.stack()\n",
    "tmp.columns = ['item_to_last_sold_month']\n",
    "tmp.reset_index(inplace=True)\n",
    "tmp = tmp[['month', 'item_id', 'item_to_last_sold_month']]\n",
    "\n",
    "x = pd.merge(x, tmp, on=['month', 'item_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    x.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    x.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test sets\n",
    "x_train = x.loc[(x['month']<=32) & (x['month']>=12), :].copy()\n",
    "x_val = x.loc[x['month']==33, :].copy()\n",
    "x_test = x.loc[x['month']==34, :].copy()\n",
    "\n",
    "# Drop target from test set\n",
    "x_test.drop(['sales_month'], axis=1, inplace=True)\n",
    "\n",
    "# Split target from train set\n",
    "# Note that target is first clipped to (0, 40), then clipped to (0, 20) in test set. \n",
    "# This is similar to the idea of calibration\n",
    "y_train = x_train['sales_month'].clip(0, 40)\n",
    "x_train.drop(['sales_month'], axis=1, inplace=True)\n",
    "\n",
    "y_val = x_val['sales_month'].clip(0, 40)\n",
    "x_val.drop(['sales_month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth':8, \n",
    "         'subsample':0.8,\n",
    "         'min_child_weight':10,\n",
    "         'eta':0.1, \n",
    "         'lambda':2,\n",
    "         'colsample_bytree':0.8,\n",
    "         'seed':1,\n",
    "         'silent':1,\n",
    "         'maximize': False,\n",
    "         'nthread':8}\n",
    "\n",
    "n_tree = 40\n",
    "verbose = True\n",
    "n_split = 3\n",
    "n_repetition = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.1475\tval-rmse:1.14863\ttrain-clip-rmse:1.1475\tval-clip-rmse:1.14863\n",
      "[1]\ttrain-rmse:1.0978\tval-rmse:1.09988\ttrain-clip-rmse:1.0978\tval-clip-rmse:1.09988\n",
      "[2]\ttrain-rmse:1.05737\tval-rmse:1.06064\ttrain-clip-rmse:1.05737\tval-clip-rmse:1.06064\n",
      "[3]\ttrain-rmse:1.02113\tval-rmse:1.02512\ttrain-clip-rmse:1.02113\tval-clip-rmse:1.02512\n",
      "[4]\ttrain-rmse:0.991895\tval-rmse:0.996722\ttrain-clip-rmse:0.991895\tval-clip-rmse:0.996722\n",
      "[5]\ttrain-rmse:0.964623\tval-rmse:0.970438\ttrain-clip-rmse:0.964623\tval-clip-rmse:0.970438\n",
      "[6]\ttrain-rmse:0.943484\tval-rmse:0.949982\ttrain-clip-rmse:0.943485\tval-clip-rmse:0.949982\n",
      "[7]\ttrain-rmse:0.923016\tval-rmse:0.930287\ttrain-clip-rmse:0.923016\tval-clip-rmse:0.930287\n",
      "[8]\ttrain-rmse:0.90582\tval-rmse:0.913752\ttrain-clip-rmse:0.90582\tval-clip-rmse:0.913753\n",
      "[9]\ttrain-rmse:0.892964\tval-rmse:0.901661\ttrain-clip-rmse:0.892963\tval-clip-rmse:0.901661\n",
      "[10]\ttrain-rmse:0.88113\tval-rmse:0.890496\ttrain-clip-rmse:0.88113\tval-clip-rmse:0.890496\n",
      "[11]\ttrain-rmse:0.869647\tval-rmse:0.879675\ttrain-clip-rmse:0.869647\tval-clip-rmse:0.879675\n",
      "[12]\ttrain-rmse:0.86039\tval-rmse:0.870933\ttrain-clip-rmse:0.86039\tval-clip-rmse:0.870933\n",
      "[13]\ttrain-rmse:0.850261\tval-rmse:0.861354\ttrain-clip-rmse:0.850261\tval-clip-rmse:0.861354\n",
      "[14]\ttrain-rmse:0.841919\tval-rmse:0.853636\ttrain-clip-rmse:0.841919\tval-clip-rmse:0.853636\n",
      "[15]\ttrain-rmse:0.836029\tval-rmse:0.848439\ttrain-clip-rmse:0.83603\tval-clip-rmse:0.848439\n",
      "[16]\ttrain-rmse:0.829809\tval-rmse:0.84269\ttrain-clip-rmse:0.829809\tval-clip-rmse:0.84269\n",
      "[17]\ttrain-rmse:0.823282\tval-rmse:0.836705\ttrain-clip-rmse:0.823283\tval-clip-rmse:0.836705\n",
      "[18]\ttrain-rmse:0.817458\tval-rmse:0.831536\ttrain-clip-rmse:0.817458\tval-clip-rmse:0.831536\n",
      "[19]\ttrain-rmse:0.812383\tval-rmse:0.826888\ttrain-clip-rmse:0.812383\tval-clip-rmse:0.826888\n",
      "[20]\ttrain-rmse:0.808042\tval-rmse:0.823307\ttrain-clip-rmse:0.808042\tval-clip-rmse:0.823308\n",
      "[21]\ttrain-rmse:0.804751\tval-rmse:0.820534\ttrain-clip-rmse:0.804751\tval-clip-rmse:0.820534\n",
      "[22]\ttrain-rmse:0.802024\tval-rmse:0.818252\ttrain-clip-rmse:0.802024\tval-clip-rmse:0.818252\n",
      "[23]\ttrain-rmse:0.798527\tval-rmse:0.815293\ttrain-clip-rmse:0.798526\tval-clip-rmse:0.815293\n",
      "[24]\ttrain-rmse:0.795166\tval-rmse:0.812362\ttrain-clip-rmse:0.795166\tval-clip-rmse:0.812362\n",
      "[25]\ttrain-rmse:0.792443\tval-rmse:0.810142\ttrain-clip-rmse:0.792443\tval-clip-rmse:0.810141\n",
      "[26]\ttrain-rmse:0.790068\tval-rmse:0.808136\ttrain-clip-rmse:0.790068\tval-clip-rmse:0.808135\n",
      "[27]\ttrain-rmse:0.787942\tval-rmse:0.806471\ttrain-clip-rmse:0.787941\tval-clip-rmse:0.80647\n",
      "[28]\ttrain-rmse:0.785139\tval-rmse:0.803849\ttrain-clip-rmse:0.785139\tval-clip-rmse:0.803849\n",
      "[29]\ttrain-rmse:0.783331\tval-rmse:0.802466\ttrain-clip-rmse:0.783331\tval-clip-rmse:0.802465\n",
      "[30]\ttrain-rmse:0.781745\tval-rmse:0.801167\ttrain-clip-rmse:0.781744\tval-clip-rmse:0.801167\n",
      "[31]\ttrain-rmse:0.780123\tval-rmse:0.799957\ttrain-clip-rmse:0.780122\tval-clip-rmse:0.799955\n",
      "[32]\ttrain-rmse:0.778604\tval-rmse:0.798793\ttrain-clip-rmse:0.778603\tval-clip-rmse:0.798791\n",
      "[33]\ttrain-rmse:0.776694\tval-rmse:0.797181\ttrain-clip-rmse:0.776692\tval-clip-rmse:0.797179\n",
      "[34]\ttrain-rmse:0.775377\tval-rmse:0.796161\ttrain-clip-rmse:0.775374\tval-clip-rmse:0.796159\n",
      "[35]\ttrain-rmse:0.774244\tval-rmse:0.795409\ttrain-clip-rmse:0.774242\tval-clip-rmse:0.795406\n",
      "[36]\ttrain-rmse:0.772877\tval-rmse:0.794328\ttrain-clip-rmse:0.772874\tval-clip-rmse:0.794325\n",
      "[37]\ttrain-rmse:0.771372\tval-rmse:0.793015\ttrain-clip-rmse:0.771368\tval-clip-rmse:0.793011\n",
      "[38]\ttrain-rmse:0.770002\tval-rmse:0.791891\ttrain-clip-rmse:0.769997\tval-clip-rmse:0.791887\n",
      "[39]\ttrain-rmse:0.768839\tval-rmse:0.791055\ttrain-clip-rmse:0.768834\tval-clip-rmse:0.791049\n",
      "[40]\ttrain-rmse:0.767314\tval-rmse:0.789739\ttrain-clip-rmse:0.767307\tval-clip-rmse:0.789732\n",
      "[41]\ttrain-rmse:0.766371\tval-rmse:0.789109\ttrain-clip-rmse:0.766363\tval-clip-rmse:0.7891\n",
      "[42]\ttrain-rmse:0.765314\tval-rmse:0.788291\ttrain-clip-rmse:0.765303\tval-clip-rmse:0.788281\n",
      "[43]\ttrain-rmse:0.764411\tval-rmse:0.78758\ttrain-clip-rmse:0.7644\tval-clip-rmse:0.787569\n",
      "[44]\ttrain-rmse:0.763622\tval-rmse:0.78701\ttrain-clip-rmse:0.763609\tval-clip-rmse:0.786997\n",
      "[45]\ttrain-rmse:0.762349\tval-rmse:0.785951\ttrain-clip-rmse:0.762334\tval-clip-rmse:0.785938\n",
      "[46]\ttrain-rmse:0.76159\tval-rmse:0.78541\ttrain-clip-rmse:0.761574\tval-clip-rmse:0.785395\n",
      "[47]\ttrain-rmse:0.760655\tval-rmse:0.784685\ttrain-clip-rmse:0.760638\tval-clip-rmse:0.784669\n",
      "[48]\ttrain-rmse:0.76018\tval-rmse:0.78437\ttrain-clip-rmse:0.760161\tval-clip-rmse:0.784353\n",
      "[49]\ttrain-rmse:0.759153\tval-rmse:0.783491\ttrain-clip-rmse:0.759132\tval-clip-rmse:0.783471\n",
      "[50]\ttrain-rmse:0.757704\tval-rmse:0.782349\ttrain-clip-rmse:0.757681\tval-clip-rmse:0.782326\n",
      "[51]\ttrain-rmse:0.756891\tval-rmse:0.781714\ttrain-clip-rmse:0.756865\tval-clip-rmse:0.781688\n",
      "[52]\ttrain-rmse:0.756151\tval-rmse:0.781111\ttrain-clip-rmse:0.756123\tval-clip-rmse:0.781083\n",
      "[53]\ttrain-rmse:0.754644\tval-rmse:0.779849\ttrain-clip-rmse:0.754615\tval-clip-rmse:0.77982\n",
      "[54]\ttrain-rmse:0.754064\tval-rmse:0.779426\ttrain-clip-rmse:0.754033\tval-clip-rmse:0.779395\n",
      "[55]\ttrain-rmse:0.753309\tval-rmse:0.778833\ttrain-clip-rmse:0.753274\tval-clip-rmse:0.778799\n",
      "[56]\ttrain-rmse:0.752487\tval-rmse:0.778218\ttrain-clip-rmse:0.752449\tval-clip-rmse:0.77818\n",
      "[57]\ttrain-rmse:0.751617\tval-rmse:0.77758\ttrain-clip-rmse:0.751577\tval-clip-rmse:0.777539\n",
      "[58]\ttrain-rmse:0.750946\tval-rmse:0.777235\ttrain-clip-rmse:0.750906\tval-clip-rmse:0.777193\n",
      "[59]\ttrain-rmse:0.750077\tval-rmse:0.77655\ttrain-clip-rmse:0.750035\tval-clip-rmse:0.776506\n",
      "[60]\ttrain-rmse:0.749418\tval-rmse:0.776107\ttrain-clip-rmse:0.749372\tval-clip-rmse:0.776061\n",
      "[61]\ttrain-rmse:0.748769\tval-rmse:0.775657\ttrain-clip-rmse:0.748722\tval-clip-rmse:0.775609\n",
      "[62]\ttrain-rmse:0.748146\tval-rmse:0.775241\ttrain-clip-rmse:0.748098\tval-clip-rmse:0.775192\n",
      "[63]\ttrain-rmse:0.747524\tval-rmse:0.774748\ttrain-clip-rmse:0.747474\tval-clip-rmse:0.774696\n",
      "[64]\ttrain-rmse:0.74709\tval-rmse:0.774471\ttrain-clip-rmse:0.747038\tval-clip-rmse:0.774418\n",
      "[65]\ttrain-rmse:0.746179\tval-rmse:0.773634\ttrain-clip-rmse:0.746125\tval-clip-rmse:0.773578\n",
      "[66]\ttrain-rmse:0.745447\tval-rmse:0.773019\ttrain-clip-rmse:0.745392\tval-clip-rmse:0.772961\n",
      "[67]\ttrain-rmse:0.744985\tval-rmse:0.772719\ttrain-clip-rmse:0.744929\tval-clip-rmse:0.77266\n",
      "[68]\ttrain-rmse:0.744603\tval-rmse:0.772409\ttrain-clip-rmse:0.744546\tval-clip-rmse:0.772347\n",
      "[69]\ttrain-rmse:0.744168\tval-rmse:0.772139\ttrain-clip-rmse:0.744109\tval-clip-rmse:0.772076\n",
      "[70]\ttrain-rmse:0.743476\tval-rmse:0.771611\ttrain-clip-rmse:0.743415\tval-clip-rmse:0.771546\n",
      "[71]\ttrain-rmse:0.743034\tval-rmse:0.771383\ttrain-clip-rmse:0.742972\tval-clip-rmse:0.771318\n",
      "[72]\ttrain-rmse:0.742536\tval-rmse:0.771117\ttrain-clip-rmse:0.742472\tval-clip-rmse:0.771051\n",
      "[73]\ttrain-rmse:0.741306\tval-rmse:0.769976\ttrain-clip-rmse:0.741237\tval-clip-rmse:0.769905\n",
      "[74]\ttrain-rmse:0.740669\tval-rmse:0.769528\ttrain-clip-rmse:0.740599\tval-clip-rmse:0.769454\n",
      "[75]\ttrain-rmse:0.740456\tval-rmse:0.769421\ttrain-clip-rmse:0.740386\tval-clip-rmse:0.769347\n",
      "[76]\ttrain-rmse:0.740144\tval-rmse:0.769174\ttrain-clip-rmse:0.740074\tval-clip-rmse:0.769099\n",
      "[77]\ttrain-rmse:0.739839\tval-rmse:0.768973\ttrain-clip-rmse:0.739767\tval-clip-rmse:0.768897\n",
      "[78]\ttrain-rmse:0.739333\tval-rmse:0.768737\ttrain-clip-rmse:0.73926\tval-clip-rmse:0.76866\n",
      "[79]\ttrain-rmse:0.739163\tval-rmse:0.768627\ttrain-clip-rmse:0.73909\tval-clip-rmse:0.76855\n",
      "[80]\ttrain-rmse:0.73858\tval-rmse:0.768293\ttrain-clip-rmse:0.738506\tval-clip-rmse:0.768215\n",
      "[81]\ttrain-rmse:0.738028\tval-rmse:0.767891\ttrain-clip-rmse:0.737953\tval-clip-rmse:0.76781\n",
      "[82]\ttrain-rmse:0.737681\tval-rmse:0.767693\ttrain-clip-rmse:0.737605\tval-clip-rmse:0.767611\n",
      "[83]\ttrain-rmse:0.736559\tval-rmse:0.766827\ttrain-clip-rmse:0.73648\tval-clip-rmse:0.766742\n",
      "[84]\ttrain-rmse:0.736342\tval-rmse:0.76672\ttrain-clip-rmse:0.736263\tval-clip-rmse:0.766635\n",
      "[85]\ttrain-rmse:0.735234\tval-rmse:0.765733\ttrain-clip-rmse:0.735151\tval-clip-rmse:0.765645\n",
      "[86]\ttrain-rmse:0.734872\tval-rmse:0.765525\ttrain-clip-rmse:0.73479\tval-clip-rmse:0.765437\n",
      "[87]\ttrain-rmse:0.734312\tval-rmse:0.765156\ttrain-clip-rmse:0.734228\tval-clip-rmse:0.765065\n",
      "[88]\ttrain-rmse:0.734251\tval-rmse:0.765126\ttrain-clip-rmse:0.734167\tval-clip-rmse:0.765036\n",
      "[89]\ttrain-rmse:0.733442\tval-rmse:0.764392\ttrain-clip-rmse:0.733355\tval-clip-rmse:0.7643\n",
      "[90]\ttrain-rmse:0.732748\tval-rmse:0.763913\ttrain-clip-rmse:0.732657\tval-clip-rmse:0.763816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91]\ttrain-rmse:0.732156\tval-rmse:0.763409\ttrain-clip-rmse:0.732064\tval-clip-rmse:0.76331\n",
      "[92]\ttrain-rmse:0.731695\tval-rmse:0.763137\ttrain-clip-rmse:0.731602\tval-clip-rmse:0.763036\n",
      "[93]\ttrain-rmse:0.73149\tval-rmse:0.763025\ttrain-clip-rmse:0.731395\tval-clip-rmse:0.762924\n",
      "[94]\ttrain-rmse:0.731129\tval-rmse:0.762776\ttrain-clip-rmse:0.731033\tval-clip-rmse:0.762673\n",
      "[95]\ttrain-rmse:0.730752\tval-rmse:0.762583\ttrain-clip-rmse:0.730654\tval-clip-rmse:0.762477\n",
      "[96]\ttrain-rmse:0.730587\tval-rmse:0.762501\ttrain-clip-rmse:0.730486\tval-clip-rmse:0.762392\n",
      "[97]\ttrain-rmse:0.730331\tval-rmse:0.762324\ttrain-clip-rmse:0.730229\tval-clip-rmse:0.762214\n",
      "[98]\ttrain-rmse:0.730092\tval-rmse:0.762222\ttrain-clip-rmse:0.729989\tval-clip-rmse:0.762111\n",
      "[99]\ttrain-rmse:0.729948\tval-rmse:0.762154\ttrain-clip-rmse:0.729845\tval-clip-rmse:0.762043\n",
      "[100]\ttrain-rmse:0.729702\tval-rmse:0.761962\ttrain-clip-rmse:0.729598\tval-clip-rmse:0.761851\n",
      "[101]\ttrain-rmse:0.729465\tval-rmse:0.76176\ttrain-clip-rmse:0.729361\tval-clip-rmse:0.761649\n",
      "[102]\ttrain-rmse:0.729026\tval-rmse:0.761494\ttrain-clip-rmse:0.728921\tval-clip-rmse:0.761381\n",
      "[103]\ttrain-rmse:0.728689\tval-rmse:0.76133\ttrain-clip-rmse:0.728583\tval-clip-rmse:0.761216\n",
      "[104]\ttrain-rmse:0.728539\tval-rmse:0.761257\ttrain-clip-rmse:0.728433\tval-clip-rmse:0.76114\n",
      "[105]\ttrain-rmse:0.728286\tval-rmse:0.76115\ttrain-clip-rmse:0.72818\tval-clip-rmse:0.761033\n",
      "[106]\ttrain-rmse:0.728016\tval-rmse:0.760983\ttrain-clip-rmse:0.727909\tval-clip-rmse:0.760866\n",
      "[107]\ttrain-rmse:0.727813\tval-rmse:0.760823\ttrain-clip-rmse:0.727703\tval-clip-rmse:0.760703\n",
      "[108]\ttrain-rmse:0.727313\tval-rmse:0.760457\ttrain-clip-rmse:0.727203\tval-clip-rmse:0.760336\n",
      "[109]\ttrain-rmse:0.726874\tval-rmse:0.760173\ttrain-clip-rmse:0.726763\tval-clip-rmse:0.760051\n",
      "[110]\ttrain-rmse:0.726308\tval-rmse:0.759689\ttrain-clip-rmse:0.726196\tval-clip-rmse:0.759565\n",
      "[111]\ttrain-rmse:0.726035\tval-rmse:0.759519\ttrain-clip-rmse:0.72592\tval-clip-rmse:0.759393\n",
      "[112]\ttrain-rmse:0.725395\tval-rmse:0.758947\ttrain-clip-rmse:0.725276\tval-clip-rmse:0.758817\n",
      "[113]\ttrain-rmse:0.725282\tval-rmse:0.758882\ttrain-clip-rmse:0.725161\tval-clip-rmse:0.75875\n",
      "[114]\ttrain-rmse:0.724345\tval-rmse:0.758097\ttrain-clip-rmse:0.724223\tval-clip-rmse:0.757964\n",
      "[115]\ttrain-rmse:0.724143\tval-rmse:0.758\ttrain-clip-rmse:0.724021\tval-clip-rmse:0.757865\n",
      "[116]\ttrain-rmse:0.723839\tval-rmse:0.75789\ttrain-clip-rmse:0.723717\tval-clip-rmse:0.757755\n",
      "[117]\ttrain-rmse:0.723483\tval-rmse:0.757651\ttrain-clip-rmse:0.72336\tval-clip-rmse:0.757515\n",
      "[118]\ttrain-rmse:0.723211\tval-rmse:0.757584\ttrain-clip-rmse:0.723088\tval-clip-rmse:0.757448\n",
      "[119]\ttrain-rmse:0.722766\tval-rmse:0.757333\ttrain-clip-rmse:0.722642\tval-clip-rmse:0.757196\n",
      "[120]\ttrain-rmse:0.722469\tval-rmse:0.757166\ttrain-clip-rmse:0.722343\tval-clip-rmse:0.757027\n",
      "[121]\ttrain-rmse:0.722401\tval-rmse:0.757153\ttrain-clip-rmse:0.722276\tval-clip-rmse:0.757014\n",
      "[122]\ttrain-rmse:0.721854\tval-rmse:0.756789\ttrain-clip-rmse:0.721727\tval-clip-rmse:0.756649\n",
      "[123]\ttrain-rmse:0.721822\tval-rmse:0.756777\ttrain-clip-rmse:0.721695\tval-clip-rmse:0.756635\n",
      "[124]\ttrain-rmse:0.72097\tval-rmse:0.756094\ttrain-clip-rmse:0.720842\tval-clip-rmse:0.755951\n",
      "[125]\ttrain-rmse:0.720084\tval-rmse:0.755361\ttrain-clip-rmse:0.719953\tval-clip-rmse:0.755216\n",
      "[126]\ttrain-rmse:0.719881\tval-rmse:0.755252\ttrain-clip-rmse:0.71975\tval-clip-rmse:0.755105\n",
      "[127]\ttrain-rmse:0.719512\tval-rmse:0.755072\ttrain-clip-rmse:0.71938\tval-clip-rmse:0.754923\n",
      "[128]\ttrain-rmse:0.719371\tval-rmse:0.755043\ttrain-clip-rmse:0.719239\tval-clip-rmse:0.754893\n",
      "[129]\ttrain-rmse:0.719026\tval-rmse:0.754858\ttrain-clip-rmse:0.718892\tval-clip-rmse:0.754707\n",
      "[130]\ttrain-rmse:0.718883\tval-rmse:0.75479\ttrain-clip-rmse:0.718749\tval-clip-rmse:0.754638\n",
      "[131]\ttrain-rmse:0.718271\tval-rmse:0.754306\ttrain-clip-rmse:0.718135\tval-clip-rmse:0.754152\n",
      "[132]\ttrain-rmse:0.718164\tval-rmse:0.754284\ttrain-clip-rmse:0.718028\tval-clip-rmse:0.754128\n",
      "[133]\ttrain-rmse:0.717495\tval-rmse:0.753734\ttrain-clip-rmse:0.717355\tval-clip-rmse:0.753574\n",
      "[134]\ttrain-rmse:0.717419\tval-rmse:0.753722\ttrain-clip-rmse:0.717279\tval-clip-rmse:0.753562\n",
      "[135]\ttrain-rmse:0.717285\tval-rmse:0.753688\ttrain-clip-rmse:0.717145\tval-clip-rmse:0.753529\n",
      "[136]\ttrain-rmse:0.716725\tval-rmse:0.753252\ttrain-clip-rmse:0.716582\tval-clip-rmse:0.75309\n",
      "[137]\ttrain-rmse:0.716629\tval-rmse:0.753208\ttrain-clip-rmse:0.716486\tval-clip-rmse:0.753045\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-d13ea4c55a07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_repetition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gain'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-0c6e987cd55f>\u001b[0m in \u001b[0;36mcv\u001b[1;34m(x_train, y_train, param, n_repetition, n_split, n_tree, verbose, random_state)\u001b[0m\n\u001b[0;32m     27\u001b[0m                                   \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                                   \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclip_rmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaximize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                                   evals_result=cv_results[m, n], verbose_eval=verbose)\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mrunning_time\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\xgboost-0.72-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\xgboost-0.72-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\xgboost-0.72-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    895\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m--> 897\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m    898\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    df, clf, running_time = cv(x_train, y_train, param, n_repetition, n_split, n_tree, verbose, 42)\n",
    "    \n",
    "    a = {k: clf[k].get_score(importance_type='gain') for k in clf.keys()}\n",
    "\n",
    "    b = pd.DataFrame(a)\n",
    "\n",
    "    b.columns = list(range(n_split))\n",
    "\n",
    "    c = b.mean(axis=1).sort_values(ascending=False)\n",
    "\n",
    "    d = c.head(50).index.tolist()\n",
    "    e = []\n",
    "    f = []\n",
    "    for n in d:\n",
    "        if len(n.split('_'))>=2 and n.split('_')[-2] == 'lag':\n",
    "            e.append('_'.join(n.split('_')[:-2]))\n",
    "            f.append(int(n.split('_')[-1]))\n",
    "\n",
    "    e = set(e)\n",
    "    f = set(f)\n",
    "\n",
    "    b.to_csv('eda_11_7_feature_importance.csv')\n",
    "\n",
    "    plt.plot(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dval = xgb.DMatrix(x_val, y_val)\n",
    "cv_results = {}\n",
    "cv_bst = {}\n",
    "np.random.seed(42)\n",
    "for n in range(n_repetition):\n",
    "    param['seed'] = np.random.randint(10**6)\n",
    "    cv_results[n] = {}\n",
    "    cv_bst[n] = xgb.train(param, dtrain,num_boost_round=n_tree, \n",
    "        evals=[(dtrain, 'train'), (dval, 'val')], \n",
    "        feval=clip_rmse, maximize=False, early_stopping_rounds=None, \n",
    "        evals_result=cv_results[n], verbose_eval=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.38094\ttrain-clip-rmse:1.14074\n",
      "[1]\ttrain-rmse:1.31929\ttrain-clip-rmse:1.08353\n",
      "[2]\ttrain-rmse:1.26746\ttrain-clip-rmse:1.03654\n",
      "[3]\ttrain-rmse:1.22239\ttrain-clip-rmse:0.997208\n",
      "[4]\ttrain-rmse:1.18283\ttrain-clip-rmse:0.963882\n",
      "[5]\ttrain-rmse:1.1518\ttrain-clip-rmse:0.938717\n",
      "[6]\ttrain-rmse:1.12555\ttrain-clip-rmse:0.918386\n",
      "[7]\ttrain-rmse:1.10008\ttrain-clip-rmse:0.899507\n",
      "[8]\ttrain-rmse:1.07885\ttrain-clip-rmse:0.883971\n",
      "[9]\ttrain-rmse:1.06068\ttrain-clip-rmse:0.871127\n",
      "[10]\ttrain-rmse:1.0442\ttrain-clip-rmse:0.859605\n",
      "[11]\ttrain-rmse:1.03095\ttrain-clip-rmse:0.850772\n",
      "[12]\ttrain-rmse:1.01839\ttrain-clip-rmse:0.842295\n",
      "[13]\ttrain-rmse:1.00737\ttrain-clip-rmse:0.835085\n",
      "[14]\ttrain-rmse:0.999075\ttrain-clip-rmse:0.829577\n",
      "[15]\ttrain-rmse:0.991949\ttrain-clip-rmse:0.82519\n",
      "[16]\ttrain-rmse:0.983952\ttrain-clip-rmse:0.820029\n",
      "[17]\ttrain-rmse:0.976724\ttrain-clip-rmse:0.815841\n",
      "[18]\ttrain-rmse:0.970413\ttrain-clip-rmse:0.812025\n",
      "[19]\ttrain-rmse:0.965573\ttrain-clip-rmse:0.809196\n",
      "[20]\ttrain-rmse:0.960042\ttrain-clip-rmse:0.805758\n",
      "[21]\ttrain-rmse:0.954677\ttrain-clip-rmse:0.80277\n",
      "[22]\ttrain-rmse:0.949886\ttrain-clip-rmse:0.800132\n",
      "[23]\ttrain-rmse:0.945848\ttrain-clip-rmse:0.797762\n",
      "[24]\ttrain-rmse:0.942213\ttrain-clip-rmse:0.79594\n",
      "[25]\ttrain-rmse:0.939731\ttrain-clip-rmse:0.794407\n",
      "[26]\ttrain-rmse:0.936433\ttrain-clip-rmse:0.792316\n",
      "[27]\ttrain-rmse:0.932786\ttrain-clip-rmse:0.790218\n",
      "[28]\ttrain-rmse:0.928742\ttrain-clip-rmse:0.787752\n",
      "[29]\ttrain-rmse:0.926116\ttrain-clip-rmse:0.786365\n",
      "[30]\ttrain-rmse:0.92308\ttrain-clip-rmse:0.784604\n",
      "[31]\ttrain-rmse:0.92\ttrain-clip-rmse:0.783046\n",
      "[32]\ttrain-rmse:0.917852\ttrain-clip-rmse:0.78164\n",
      "[33]\ttrain-rmse:0.915938\ttrain-clip-rmse:0.780569\n",
      "[34]\ttrain-rmse:0.912353\ttrain-clip-rmse:0.778418\n",
      "[35]\ttrain-rmse:0.911151\ttrain-clip-rmse:0.777662\n",
      "[36]\ttrain-rmse:0.909012\ttrain-clip-rmse:0.776473\n",
      "[37]\ttrain-rmse:0.906598\ttrain-clip-rmse:0.775124\n",
      "[38]\ttrain-rmse:0.905279\ttrain-clip-rmse:0.774346\n",
      "[39]\ttrain-rmse:0.902343\ttrain-clip-rmse:0.772469\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    x_train = x.loc[(x['month']<=33) & (x['month']>=12), :].copy()\n",
    "    x_test = x.loc[x['month']==34, :].copy()\n",
    "\n",
    "    # Drop target from test set\n",
    "    x_test.drop(['sales_month'], axis=1, inplace=True)\n",
    "\n",
    "    y_train = x_train['sales_month'].clip(0, 40)\n",
    "    x_train.drop(['sales_month'], axis=1, inplace=True)\n",
    "    \n",
    "    dtrain = xgb.DMatrix(x_train, y_train)\n",
    "    bst = xgb.train(param, dtrain, num_boost_round=n_tree, \n",
    "                    evals=[(dtrain, 'train')], feval=clip_rmse, maximize=False,\n",
    "                    verbose_eval=True)\n",
    "\n",
    "    preds = bst.predict(xgb.DMatrix(x_test))\n",
    "    preds = list(map(lambda x: min(20, max(x, 0)), list(preds)))\n",
    "    sub_df = pd.DataFrame({'ID': test.index, 'item_cnt_month': preds})\n",
    "    sub_df.to_csv('eda_11_7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
