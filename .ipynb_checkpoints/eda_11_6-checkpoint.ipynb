{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import gc\n",
    "import itertools\n",
    "import tqdm\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import scipy.stats as ss\n",
    "from numba import jit\n",
    "\n",
    "if os.name=='nt':\n",
    "    try:\n",
    "        mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin'\n",
    "        os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_features(df, lags, merge_cols, shift_cols, fillna_value=None):\n",
    "    '''create lag features of col'''\n",
    "    cols = copy.copy(merge_cols)\n",
    "    cols.extend(shift_cols)\n",
    "    tmp = df.loc[:, cols]\n",
    "    for i in lags:\n",
    "        shifted = tmp.copy()\n",
    "        shifted_cols = shifted.columns.tolist()\n",
    "        shifted_cols = [c+'_lag_'+str(i) if c in shift_cols else c \n",
    "                        for c in shifted_cols]\n",
    "        shifted.columns = shifted_cols\n",
    "        shifted['month'] += i\n",
    "        shifted.drop_duplicates(inplace=True)\n",
    "        df = pd.merge(df, shifted, on=merge_cols, how='left')\n",
    "    if fillna_value is not None:\n",
    "        df.fillna(fillna_value, inplace=True)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_rmse(preds, dtrain):\n",
    "    y_test = np.array(dtrain.get_label())\n",
    "    preds = np.array(preds)\n",
    "    y_test = np.maximum(np.minimum(y_test, 20), 0)\n",
    "    preds = np.maximum(np.minimum(preds, 20), 0)\n",
    "    #preds = np.array(list(map(lambda x: min(20, max(x, 0)), list(preds))))\n",
    "    #y_test = np.array(list(map(lambda x: min(20, max(x, 0)), list(y_test))))\n",
    "    rmse = np.sqrt(mean_squared_error(preds,y_test))\n",
    "    return 'clip-rmse', rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(x_train, y_train, param, n_repetition, n_split, n_tree, verbose, random_state):\n",
    "    '''Repeated CV'''\n",
    "    \n",
    "    cv_results = {}\n",
    "    clf = {}\n",
    "    running_time = {}\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    for m in range(n_repetition):\n",
    "        # Train and valuation sets split\n",
    "        skf = StratifiedKFold(n_splits=n_split, random_state=np.random.randint(10**6), shuffle=True)\n",
    "\n",
    "        for n, (train_index, val_index) in enumerate(skf.split(x_train, y_train)):\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Construct DMatrix\n",
    "            dtrain = xgb.DMatrix(x_train.iloc[train_index], label=y_train.iloc[train_index])\n",
    "            dval = xgb.DMatrix(x_train.iloc[val_index], label=y_train.iloc[val_index])\n",
    "\n",
    "            # Placeholder for evals_results\n",
    "            cv_results[m, n] = {}\n",
    "\n",
    "            param['seed'] = np.random.randint(10**6)\n",
    "            clf[m, n] = xgb.train(param, dtrain,num_boost_round=n_tree, \n",
    "                                  evals=[(dtrain, 'train'), (dval, 'val')], \n",
    "                                  feval=clip_rmse, maximize=False, early_stopping_rounds=None, \n",
    "                                  evals_result=cv_results[m, n], verbose_eval=verbose)\n",
    "\n",
    "            running_time[m, n] = time.time() - start_time\n",
    "\n",
    "            print('Repeat {}, split {}, val score = {:.3f}, running time = {:.3f} min.'.format(m, n, \n",
    "                cv_results[m, n]['val']['clip-rmse'][-1], running_time[m, n]/60))\n",
    "\n",
    "    cv_results_final = {}\n",
    "    for m in range(n_repetition):\n",
    "        for n in range(n_split):\n",
    "            cv_results_final['train', m, n] = cv_results[m, n]['train']['clip-rmse']\n",
    "            cv_results_final['val', m, n] = cv_results[m, n]['val']['clip-rmse']\n",
    "\n",
    "    df = pd.DataFrame(cv_results_final)\n",
    "    df.index.name = 'iteration'\n",
    "    df.columns.names = ['dataset', 'repetition', 'cv_split']\n",
    "\n",
    "    print('Val mean = {:.3f}, std = {:.3f}'.format(df['val'].iloc[-1].mean(), df['val'].iloc[-1].std()))\n",
    "    \n",
    "    return df, clf, running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_combination(x, feature_list, function_dict, column_name, merge=False):\n",
    "    '''Combination of new features'''\n",
    "    tmp = x.groupby(feature_list).agg(function_dict)\n",
    "    tmp.columns = column_name\n",
    "    if merge:\n",
    "        x = x.merge(tmp, on=feature_list, how='left')\n",
    "        return x, tmp\n",
    "    else:\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('all/sales_train.csv.gz')\n",
    "test = pd.read_csv('all/test.csv.gz')\n",
    "shop = pd.read_csv('all/shops-translated.csv')\n",
    "item = pd.read_csv('all/item_category.csv')\n",
    "\n",
    "test.set_index('ID', inplace=True)\n",
    "item.drop(['item_name_translated'], axis=1, inplace=True)\n",
    "shop.drop(['Name'], axis=1, inplace=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "item['item_cat1'] = le.fit_transform(item['item_cat1'].astype(str))\n",
    "item['item_cat2'] = le.fit_transform(item['item_cat2'].astype(str))\n",
    "shop['City'] = le.fit_transform(shop['City'])\n",
    "shop['Type'] = le.fit_transform(shop['Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.item_price<100000]\n",
    "train = train[train.item_cnt_day<1001]\n",
    "median = train[(train.shop_id==32)&(train.item_id==2973)&(train.date_block_num==4)&(train.item_price>0)].item_price.median()\n",
    "train.loc[train.item_price<0, 'item_price'] = median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix shop names and ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "train.loc[train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monthly sales for all the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(train.groupby(['date_block_num', 'shop_id', 'item_id'])['item_cnt_day'].sum())\n",
    "\n",
    "x.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set only contains sold samples, need to extend to all samples.\n",
    "\n",
    "There are two ways of extending:\n",
    "1. overall product between elements in (month, shop_id, item_id)\n",
    "2. in each month, the product between elements in (shop_id, item_id)\n",
    "\n",
    "The first one increases the number of rows by 23.5 times, the second one 6 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall product count is 42260028, sample count is 1609123, ratio is 26.263\n",
      "monthly product count sum is 10913804, monthly sample count is 1609123, ratio is 6.782\n"
     ]
    }
   ],
   "source": [
    "shop_count = {}\n",
    "item_count = {}\n",
    "product_count = {}\n",
    "sample_count = {}\n",
    "ratio = {}\n",
    "\n",
    "for n in x.date_block_num.unique():\n",
    "    shop_count[n] = len(x.loc[x.date_block_num==n, 'shop_id'].unique())\n",
    "    item_count[n] = len(x.loc[x.date_block_num==n, 'item_id'].unique())\n",
    "    sample_count[n] = len(x.loc[x.date_block_num==n, :])\n",
    "    product_count[n] = shop_count[n]*item_count[n]\n",
    "    ratio[n] = product_count[n]/sample_count[n]\n",
    "#     print('product count is {}, sample count is {}, ratio is {:.3f}'.format(product_count[n], \n",
    "#                                                                             sample_count[n], \n",
    "#                                                                             product_count[n]/sample_count[n]))\n",
    "    \n",
    "print('overall product count is {}, sample count is {}, ratio is {:.3f}'.format(\n",
    "    len(x.shop_id.unique())*len(x.item_id.unique())*34, \n",
    "    x.shape[0], 34*len(x.shop_id.unique())*len(x.item_id.unique())/x.shape[0]))\n",
    "print('monthly product count sum is {}, monthly sample count is {}, ratio is {:.3f}'.format(\n",
    "    sum(product_count.values()), sum(sample_count.values()), sum(product_count.values())/sum(sample_count.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the first extending method\n",
    "\n",
    "It requires huge RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    month = np.arange(0, 34)\n",
    "    shop_list = train.shop_id.unique().tolist()\n",
    "    item_list = train.item_id.unique().tolist()\n",
    "    n_rows = len(month)*len(shop_list)*len(item_list)\n",
    "\n",
    "    idx = pd.MultiIndex.from_product([month, shop_list, item_list], names=['date_block_num', 'shop_id', 'item_id'])\n",
    "\n",
    "    x2 = pd.DataFrame(np.zeros((n_rows,2)), index=idx)\n",
    "    x2.reset_index(inplace=True, drop=False)\n",
    "    x2.drop([0, 1], axis=1, inplace=True)\n",
    "\n",
    "    x = x2.merge(x, on=['date_block_num', 'shop_id', 'item_id'], how='outer').fillna(0.0)\n",
    "    test['date_block_num'] = 34\n",
    "    x = pd.concat((x, test), sort=False).fillna(0.0)\n",
    "\n",
    "    del x2\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the second method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for n in range(34):\n",
    "    shop_list = x.loc[x.date_block_num==n, 'shop_id'].unique()\n",
    "    item_list = x.loc[x.date_block_num==n, 'item_id'].unique()\n",
    "    idx = pd.MultiIndex.from_product([[n], shop_list, item_list], names=['date_block_num', 'shop_id', 'item_id'])\n",
    "    df_tmp = pd.DataFrame(np.zeros((len(idx),2)), index=idx)\n",
    "    tmp.append(df_tmp)\n",
    "tmp = pd.concat(tmp, sort=False)\n",
    "tmp.reset_index(inplace=True, drop=False)\n",
    "tmp.drop([0, 1], axis=1, inplace=True)\n",
    "x = tmp.merge(x, on=['date_block_num', 'shop_id', 'item_id'], how='outer').fillna(0.0)\n",
    "test['date_block_num'] = 34\n",
    "x = pd.concat((x, test), sort=False).fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add shop/item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.merge(x, shop, on='shop_id', how='left')\n",
    "x = pd.merge(x, item, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns = ['month', 'shop_id', 'item_id', 'sales_month', \n",
    "             'City', 'Type', 'item_cat1', 'item_cat2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['City'] = x['City'].astype(np.int8)\n",
    "x['Type'] = x['Type'].astype(np.int8)\n",
    "x['item_cat1'] = x['item_cat1'].astype(np.int8)\n",
    "x['item_cat2'] = x['item_cat2'].astype(np.int8)\n",
    "x['sales_month'] = x['sales_month'].astype(np.float16)\n",
    "x['month'] = x['month'].astype(np.int8)\n",
    "x['shop_id'] = x['shop_id'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lag_features(x, [1, 2, 3, 6, 12], \n",
    "                 ['month', 'shop_id', 'item_id'], \n",
    "                 ['sales_month'], fillna_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = x.groupby('month').agg({'sales_month': ['mean']})\n",
    "group.columns = ['sales_mean_month']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=['month'], how='left')\n",
    "x['sales_mean_month'] = x['sales_mean_month'].astype(np.float16)\n",
    "x = lag_features(x, [1], ['month'], ['sales_mean_month'], fillna_value=0.0)\n",
    "x.drop(['sales_mean_month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_item`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_item'\n",
    "group = x.groupby(['month', 'item_id']).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=['month', 'item_id'], how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1, 2, 3, 6, 12], \n",
    "                 ['month', 'item_id'], \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_shop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_shop'\n",
    "merge_cols = ['month', 'shop_id']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1, 2, 3, 6, 12], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_cat1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_cat1'\n",
    "merge_cols = ['month', 'item_cat1']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_shop_cat1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_shop_cat1'\n",
    "merge_cols = ['month', 'shop_id', 'item_cat1']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_shop_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_shop_type'\n",
    "merge_cols = ['month', 'shop_id', 'Type']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_shop_cat2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_shop_cat2'\n",
    "merge_cols = ['month', 'shop_id', 'item_cat2']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_city`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_city'\n",
    "merge_cols = ['month', 'City']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_item_city`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_item_city'\n",
    "merge_cols = ['month', 'item_id', 'City']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_cat2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_cat2'\n",
    "merge_cols = ['month', 'item_cat2']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_cat1_cat2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_cat1_cat2'\n",
    "merge_cols = ['month', 'item_cat1', 'item_cat2']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1, 2, 3, 6], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    x.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    x.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test sets\n",
    "x_train = x.loc[(x['month']<=33) & (x['month']>=12), :].copy()\n",
    "x_test = x.loc[x['month']==34, :].copy()\n",
    "\n",
    "# Drop target from test set\n",
    "x_test.drop(['sales_month'], axis=1, inplace=True)\n",
    "\n",
    "# Split target from train set\n",
    "# Note that target is first clipped to (0, 40), then clipped to (0, 20) in test set. \n",
    "# This is similar to the idea of calibration\n",
    "y_train = x_train['sales_month'].clip(0, 40)\n",
    "x_train.drop(['sales_month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lyaa\\AppData\\Local\\Continuum\\miniconda3\\envs\\kaggle\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.38077\tval-rmse:1.38269\ttrain-clip-rmse:1.14198\tval-clip-rmse:1.14373\n",
      "[1]\ttrain-rmse:1.32717\tval-rmse:1.32967\ttrain-clip-rmse:1.09968\tval-clip-rmse:1.10217\n",
      "[2]\ttrain-rmse:1.30529\tval-rmse:1.30967\ttrain-clip-rmse:1.07973\tval-clip-rmse:1.08369\n",
      "[3]\ttrain-rmse:1.28895\tval-rmse:1.29553\ttrain-clip-rmse:1.06783\tval-clip-rmse:1.07333\n",
      "[4]\ttrain-rmse:1.27658\tval-rmse:1.28459\ttrain-clip-rmse:1.05751\tval-clip-rmse:1.06404\n",
      "[5]\ttrain-rmse:1.2366\tval-rmse:1.24587\ttrain-clip-rmse:1.03379\tval-clip-rmse:1.04127\n",
      "[6]\ttrain-rmse:1.22649\tval-rmse:1.23691\ttrain-clip-rmse:1.02608\tval-clip-rmse:1.03425\n",
      "[7]\ttrain-rmse:1.22063\tval-rmse:1.23239\ttrain-clip-rmse:1.02172\tval-clip-rmse:1.03069\n",
      "[8]\ttrain-rmse:1.21414\tval-rmse:1.22661\ttrain-clip-rmse:1.01682\tval-clip-rmse:1.0264\n",
      "[9]\ttrain-rmse:1.19775\tval-rmse:1.21175\ttrain-clip-rmse:1.01017\tval-clip-rmse:1.02048\n",
      "[10]\ttrain-rmse:1.19054\tval-rmse:1.20513\ttrain-clip-rmse:1.00498\tval-clip-rmse:1.01564\n",
      "[11]\ttrain-rmse:1.18396\tval-rmse:1.19937\ttrain-clip-rmse:1.00043\tval-clip-rmse:1.01158\n",
      "[12]\ttrain-rmse:1.18075\tval-rmse:1.19665\ttrain-clip-rmse:0.997974\tval-clip-rmse:1.00951\n",
      "[13]\ttrain-rmse:1.17311\tval-rmse:1.18976\ttrain-clip-rmse:0.994449\tval-clip-rmse:1.00658\n",
      "[14]\ttrain-rmse:1.17062\tval-rmse:1.18786\ttrain-clip-rmse:0.992517\tval-clip-rmse:1.00498\n",
      "[15]\ttrain-rmse:1.16579\tval-rmse:1.18334\ttrain-clip-rmse:0.988527\tval-clip-rmse:1.0012\n",
      "[16]\ttrain-rmse:1.16166\tval-rmse:1.17993\ttrain-clip-rmse:0.986403\tval-clip-rmse:0.999403\n",
      "[17]\ttrain-rmse:1.15809\tval-rmse:1.17695\ttrain-clip-rmse:0.984579\tval-clip-rmse:0.997949\n",
      "[18]\ttrain-rmse:1.15597\tval-rmse:1.17543\ttrain-clip-rmse:0.983303\tval-clip-rmse:0.996998\n",
      "[19]\ttrain-rmse:1.15413\tval-rmse:1.17402\ttrain-clip-rmse:0.982798\tval-clip-rmse:0.996633\n",
      "[20]\ttrain-rmse:1.14973\tval-rmse:1.17036\ttrain-clip-rmse:0.980846\tval-clip-rmse:0.994702\n",
      "[21]\ttrain-rmse:1.14793\tval-rmse:1.16829\ttrain-clip-rmse:0.979437\tval-clip-rmse:0.993108\n",
      "[22]\ttrain-rmse:1.14626\tval-rmse:1.16704\ttrain-clip-rmse:0.978209\tval-clip-rmse:0.992103\n",
      "[23]\ttrain-rmse:1.14375\tval-rmse:1.165\ttrain-clip-rmse:0.976778\tval-clip-rmse:0.990882\n",
      "[24]\ttrain-rmse:1.13872\tval-rmse:1.16045\ttrain-clip-rmse:0.973715\tval-clip-rmse:0.987934\n",
      "[25]\ttrain-rmse:1.13643\tval-rmse:1.15874\ttrain-clip-rmse:0.972141\tval-clip-rmse:0.986793\n",
      "[26]\ttrain-rmse:1.1324\tval-rmse:1.15545\ttrain-clip-rmse:0.968964\tval-clip-rmse:0.984191\n",
      "[27]\ttrain-rmse:1.13115\tval-rmse:1.15459\ttrain-clip-rmse:0.968166\tval-clip-rmse:0.983565\n",
      "[28]\ttrain-rmse:1.12992\tval-rmse:1.15379\ttrain-clip-rmse:0.967245\tval-clip-rmse:0.982981\n",
      "[29]\ttrain-rmse:1.12864\tval-rmse:1.15296\ttrain-clip-rmse:0.966382\tval-clip-rmse:0.982386\n",
      "[30]\ttrain-rmse:1.1257\tval-rmse:1.15039\ttrain-clip-rmse:0.964015\tval-clip-rmse:0.980254\n",
      "[31]\ttrain-rmse:1.12443\tval-rmse:1.14955\ttrain-clip-rmse:0.963404\tval-clip-rmse:0.979944\n",
      "[32]\ttrain-rmse:1.12056\tval-rmse:1.14602\ttrain-clip-rmse:0.961087\tval-clip-rmse:0.978031\n",
      "[33]\ttrain-rmse:1.11857\tval-rmse:1.14465\ttrain-clip-rmse:0.959848\tval-clip-rmse:0.97718\n",
      "[34]\ttrain-rmse:1.11683\tval-rmse:1.14334\ttrain-clip-rmse:0.958239\tval-clip-rmse:0.975832\n",
      "[35]\ttrain-rmse:1.11383\tval-rmse:1.14113\ttrain-clip-rmse:0.956949\tval-clip-rmse:0.974726\n",
      "[36]\ttrain-rmse:1.11274\tval-rmse:1.14038\ttrain-clip-rmse:0.956259\tval-clip-rmse:0.974271\n",
      "[37]\ttrain-rmse:1.1114\tval-rmse:1.13963\ttrain-clip-rmse:0.955304\tval-clip-rmse:0.973796\n",
      "[38]\ttrain-rmse:1.10968\tval-rmse:1.1385\ttrain-clip-rmse:0.953848\tval-clip-rmse:0.972786\n",
      "[39]\ttrain-rmse:1.10879\tval-rmse:1.13792\ttrain-clip-rmse:0.952981\tval-clip-rmse:0.972154\n",
      "[40]\ttrain-rmse:1.10699\tval-rmse:1.13644\ttrain-clip-rmse:0.952069\tval-clip-rmse:0.971329\n",
      "[41]\ttrain-rmse:1.10579\tval-rmse:1.1355\ttrain-clip-rmse:0.951052\tval-clip-rmse:0.970535\n",
      "[42]\ttrain-rmse:1.10532\tval-rmse:1.13526\ttrain-clip-rmse:0.950768\tval-clip-rmse:0.970383\n",
      "[43]\ttrain-rmse:1.10497\tval-rmse:1.13516\ttrain-clip-rmse:0.950627\tval-clip-rmse:0.970359\n",
      "[44]\ttrain-rmse:1.10238\tval-rmse:1.13301\ttrain-clip-rmse:0.948856\tval-clip-rmse:0.968873\n",
      "[45]\ttrain-rmse:1.10126\tval-rmse:1.13229\ttrain-clip-rmse:0.948227\tval-clip-rmse:0.968478\n",
      "[46]\ttrain-rmse:1.10095\tval-rmse:1.13223\ttrain-clip-rmse:0.948\tval-clip-rmse:0.96842\n",
      "[47]\ttrain-rmse:1.10054\tval-rmse:1.13207\ttrain-clip-rmse:0.947708\tval-clip-rmse:0.968304\n",
      "[48]\ttrain-rmse:1.09984\tval-rmse:1.13165\ttrain-clip-rmse:0.947285\tval-clip-rmse:0.968029\n",
      "[49]\ttrain-rmse:1.09929\tval-rmse:1.13135\ttrain-clip-rmse:0.946787\tval-clip-rmse:0.967728\n",
      "[50]\ttrain-rmse:1.09876\tval-rmse:1.13097\ttrain-clip-rmse:0.946263\tval-clip-rmse:0.967346\n",
      "[51]\ttrain-rmse:1.09514\tval-rmse:1.12753\ttrain-clip-rmse:0.944179\tval-clip-rmse:0.965234\n",
      "[52]\ttrain-rmse:1.09448\tval-rmse:1.12704\ttrain-clip-rmse:0.943722\tval-clip-rmse:0.964997\n",
      "[53]\ttrain-rmse:1.092\tval-rmse:1.12523\ttrain-clip-rmse:0.94205\tval-clip-rmse:0.96365\n",
      "[54]\ttrain-rmse:1.09167\tval-rmse:1.12488\ttrain-clip-rmse:0.941733\tval-clip-rmse:0.963298\n",
      "[55]\ttrain-rmse:1.09127\tval-rmse:1.12475\ttrain-clip-rmse:0.941368\tval-clip-rmse:0.963154\n",
      "[56]\ttrain-rmse:1.08977\tval-rmse:1.12348\ttrain-clip-rmse:0.940412\tval-clip-rmse:0.962434\n",
      "[57]\ttrain-rmse:1.08948\tval-rmse:1.12338\ttrain-clip-rmse:0.940244\tval-clip-rmse:0.962391\n",
      "[58]\ttrain-rmse:1.08926\tval-rmse:1.12331\ttrain-clip-rmse:0.940049\tval-clip-rmse:0.962315\n",
      "[59]\ttrain-rmse:1.08733\tval-rmse:1.12161\ttrain-clip-rmse:0.938661\tval-clip-rmse:0.961117\n",
      "[60]\ttrain-rmse:1.08625\tval-rmse:1.12101\ttrain-clip-rmse:0.9378\tval-clip-rmse:0.960595\n",
      "[61]\ttrain-rmse:1.08547\tval-rmse:1.12047\ttrain-clip-rmse:0.937264\tval-clip-rmse:0.960254\n",
      "[62]\ttrain-rmse:1.08507\tval-rmse:1.12026\ttrain-clip-rmse:0.936903\tval-clip-rmse:0.960044\n",
      "[63]\ttrain-rmse:1.08349\tval-rmse:1.11904\ttrain-clip-rmse:0.935416\tval-clip-rmse:0.958815\n",
      "[64]\ttrain-rmse:1.0816\tval-rmse:1.11758\ttrain-clip-rmse:0.934216\tval-clip-rmse:0.957789\n",
      "[65]\ttrain-rmse:1.08075\tval-rmse:1.11705\ttrain-clip-rmse:0.933517\tval-clip-rmse:0.957319\n",
      "[66]\ttrain-rmse:1.08049\tval-rmse:1.11689\ttrain-clip-rmse:0.93328\tval-clip-rmse:0.957175\n",
      "[67]\ttrain-rmse:1.07958\tval-rmse:1.11647\ttrain-clip-rmse:0.93266\tval-clip-rmse:0.956877\n",
      "[68]\ttrain-rmse:1.07927\tval-rmse:1.11634\ttrain-clip-rmse:0.932439\tval-clip-rmse:0.956767\n",
      "[69]\ttrain-rmse:1.07885\tval-rmse:1.11629\ttrain-clip-rmse:0.932094\tval-clip-rmse:0.956722\n",
      "[70]\ttrain-rmse:1.07859\tval-rmse:1.11623\ttrain-clip-rmse:0.93188\tval-clip-rmse:0.956685\n",
      "[71]\ttrain-rmse:1.07827\tval-rmse:1.11602\ttrain-clip-rmse:0.931669\tval-clip-rmse:0.956597\n",
      "[72]\ttrain-rmse:1.07702\tval-rmse:1.11502\ttrain-clip-rmse:0.930947\tval-clip-rmse:0.955971\n",
      "[73]\ttrain-rmse:1.07678\tval-rmse:1.11493\ttrain-clip-rmse:0.930749\tval-clip-rmse:0.955916\n",
      "[74]\ttrain-rmse:1.07632\tval-rmse:1.11458\ttrain-clip-rmse:0.930411\tval-clip-rmse:0.955694\n",
      "[75]\ttrain-rmse:1.0746\tval-rmse:1.11314\ttrain-clip-rmse:0.929264\tval-clip-rmse:0.9547\n",
      "[76]\ttrain-rmse:1.07404\tval-rmse:1.11271\ttrain-clip-rmse:0.928816\tval-clip-rmse:0.954353\n",
      "[77]\ttrain-rmse:1.07356\tval-rmse:1.11249\ttrain-clip-rmse:0.928487\tval-clip-rmse:0.954209\n",
      "[78]\ttrain-rmse:1.07181\tval-rmse:1.11104\ttrain-clip-rmse:0.927329\tval-clip-rmse:0.953109\n",
      "[79]\ttrain-rmse:1.06862\tval-rmse:1.10892\ttrain-clip-rmse:0.925314\tval-clip-rmse:0.951596\n",
      "Repeat 0, split 0, val score = 0.952, running time = 3.230 min.\n",
      "[0]\ttrain-rmse:1.37851\tval-rmse:1.38218\ttrain-clip-rmse:1.14186\tval-clip-rmse:1.14406\n",
      "[1]\ttrain-rmse:1.33584\tval-rmse:1.34279\ttrain-clip-rmse:1.10585\tval-clip-rmse:1.10963\n",
      "[2]\ttrain-rmse:1.31672\tval-rmse:1.32547\ttrain-clip-rmse:1.08809\tval-clip-rmse:1.09341\n",
      "[3]\ttrain-rmse:1.29346\tval-rmse:1.30396\ttrain-clip-rmse:1.07007\tval-clip-rmse:1.0763\n",
      "[4]\ttrain-rmse:1.25952\tval-rmse:1.273\ttrain-clip-rmse:1.0502\tval-clip-rmse:1.05762\n",
      "[5]\ttrain-rmse:1.25071\tval-rmse:1.26524\ttrain-clip-rmse:1.04289\tval-clip-rmse:1.05107\n",
      "[6]\ttrain-rmse:1.24347\tval-rmse:1.25893\ttrain-clip-rmse:1.03691\tval-clip-rmse:1.04563\n",
      "[7]\ttrain-rmse:1.23676\tval-rmse:1.25199\ttrain-clip-rmse:1.03182\tval-clip-rmse:1.04023\n",
      "[8]\ttrain-rmse:1.2277\tval-rmse:1.24401\ttrain-clip-rmse:1.0254\tval-clip-rmse:1.03445\n",
      "[9]\ttrain-rmse:1.22115\tval-rmse:1.23813\ttrain-clip-rmse:1.01995\tval-clip-rmse:1.02956\n",
      "[10]\ttrain-rmse:1.21098\tval-rmse:1.22865\ttrain-clip-rmse:1.01538\tval-clip-rmse:1.02532\n",
      "[11]\ttrain-rmse:1.19451\tval-rmse:1.21277\ttrain-clip-rmse:1.00692\tval-clip-rmse:1.01718\n",
      "[12]\ttrain-rmse:1.19309\tval-rmse:1.21148\ttrain-clip-rmse:1.00574\tval-clip-rmse:1.01614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\ttrain-rmse:1.18419\tval-rmse:1.20324\ttrain-clip-rmse:1.00092\tval-clip-rmse:1.01164\n",
      "[14]\ttrain-rmse:1.17858\tval-rmse:1.1979\ttrain-clip-rmse:0.996688\tval-clip-rmse:1.00755\n",
      "[15]\ttrain-rmse:1.17562\tval-rmse:1.19534\ttrain-clip-rmse:0.994179\tval-clip-rmse:1.00535\n",
      "[16]\ttrain-rmse:1.16928\tval-rmse:1.18894\ttrain-clip-rmse:0.98954\tval-clip-rmse:1.00069\n",
      "[17]\ttrain-rmse:1.16639\tval-rmse:1.18659\ttrain-clip-rmse:0.987803\tval-clip-rmse:0.999386\n",
      "[18]\ttrain-rmse:1.16433\tval-rmse:1.18474\ttrain-clip-rmse:0.986605\tval-clip-rmse:0.998333\n",
      "[19]\ttrain-rmse:1.16306\tval-rmse:1.18379\ttrain-clip-rmse:0.985575\tval-clip-rmse:0.997567\n",
      "[20]\ttrain-rmse:1.15879\tval-rmse:1.17984\ttrain-clip-rmse:0.984737\tval-clip-rmse:0.99691\n",
      "[21]\ttrain-rmse:1.15748\tval-rmse:1.17846\ttrain-clip-rmse:0.98385\tval-clip-rmse:0.996039\n",
      "[22]\ttrain-rmse:1.15091\tval-rmse:1.17228\ttrain-clip-rmse:0.980797\tval-clip-rmse:0.993385\n",
      "[23]\ttrain-rmse:1.14843\tval-rmse:1.17053\ttrain-clip-rmse:0.979\tval-clip-rmse:0.99201\n",
      "[24]\ttrain-rmse:1.14524\tval-rmse:1.16805\ttrain-clip-rmse:0.977249\tval-clip-rmse:0.990663\n",
      "[25]\ttrain-rmse:1.13822\tval-rmse:1.16207\ttrain-clip-rmse:0.973958\tval-clip-rmse:0.987978\n",
      "[26]\ttrain-rmse:1.13609\tval-rmse:1.16038\ttrain-clip-rmse:0.97271\tval-clip-rmse:0.987104\n",
      "[27]\ttrain-rmse:1.13317\tval-rmse:1.15786\ttrain-clip-rmse:0.970809\tval-clip-rmse:0.985467\n",
      "[28]\ttrain-rmse:1.12744\tval-rmse:1.15274\ttrain-clip-rmse:0.966868\tval-clip-rmse:0.981808\n",
      "[29]\ttrain-rmse:1.12665\tval-rmse:1.15229\ttrain-clip-rmse:0.966385\tval-clip-rmse:0.981621\n",
      "[30]\ttrain-rmse:1.12241\tval-rmse:1.14864\ttrain-clip-rmse:0.963771\tval-clip-rmse:0.979525\n",
      "[31]\ttrain-rmse:1.12113\tval-rmse:1.14765\ttrain-clip-rmse:0.962788\tval-clip-rmse:0.9788\n",
      "[32]\ttrain-rmse:1.11945\tval-rmse:1.14631\ttrain-clip-rmse:0.961962\tval-clip-rmse:0.978098\n",
      "[33]\ttrain-rmse:1.11869\tval-rmse:1.1459\ttrain-clip-rmse:0.961434\tval-clip-rmse:0.977787\n",
      "[34]\ttrain-rmse:1.1177\tval-rmse:1.1453\ttrain-clip-rmse:0.960746\tval-clip-rmse:0.977351\n",
      "[35]\ttrain-rmse:1.11625\tval-rmse:1.144\ttrain-clip-rmse:0.959769\tval-clip-rmse:0.976499\n",
      "[36]\ttrain-rmse:1.11484\tval-rmse:1.14344\ttrain-clip-rmse:0.958688\tval-clip-rmse:0.976063\n",
      "[37]\ttrain-rmse:1.11337\tval-rmse:1.14215\ttrain-clip-rmse:0.957456\tval-clip-rmse:0.974985\n",
      "[38]\ttrain-rmse:1.11301\tval-rmse:1.14201\ttrain-clip-rmse:0.957162\tval-clip-rmse:0.974864\n",
      "[39]\ttrain-rmse:1.11075\tval-rmse:1.14018\ttrain-clip-rmse:0.955946\tval-clip-rmse:0.973896\n",
      "[40]\ttrain-rmse:1.10755\tval-rmse:1.13701\ttrain-clip-rmse:0.953954\tval-clip-rmse:0.971956\n",
      "[41]\ttrain-rmse:1.10688\tval-rmse:1.13649\ttrain-clip-rmse:0.953574\tval-clip-rmse:0.971705\n",
      "[42]\ttrain-rmse:1.10549\tval-rmse:1.13545\ttrain-clip-rmse:0.952419\tval-clip-rmse:0.970944\n",
      "[43]\ttrain-rmse:1.10368\tval-rmse:1.13388\ttrain-clip-rmse:0.951062\tval-clip-rmse:0.969804\n",
      "[44]\ttrain-rmse:1.10312\tval-rmse:1.13355\ttrain-clip-rmse:0.950645\tval-clip-rmse:0.969642\n",
      "[45]\ttrain-rmse:1.1028\tval-rmse:1.13335\ttrain-clip-rmse:0.950464\tval-clip-rmse:0.969584\n",
      "[46]\ttrain-rmse:1.10208\tval-rmse:1.13298\ttrain-clip-rmse:0.950006\tval-clip-rmse:0.969383\n",
      "[47]\ttrain-rmse:1.10016\tval-rmse:1.13152\ttrain-clip-rmse:0.948629\tval-clip-rmse:0.968338\n",
      "[48]\ttrain-rmse:1.09928\tval-rmse:1.13091\ttrain-clip-rmse:0.947926\tval-clip-rmse:0.96782\n",
      "[49]\ttrain-rmse:1.0974\tval-rmse:1.12942\ttrain-clip-rmse:0.946625\tval-clip-rmse:0.966826\n",
      "[50]\ttrain-rmse:1.096\tval-rmse:1.12841\ttrain-clip-rmse:0.945655\tval-clip-rmse:0.966197\n",
      "[51]\ttrain-rmse:1.0957\tval-rmse:1.12828\ttrain-clip-rmse:0.945386\tval-clip-rmse:0.966049\n",
      "[52]\ttrain-rmse:1.0935\tval-rmse:1.12661\ttrain-clip-rmse:0.943864\tval-clip-rmse:0.964794\n",
      "[53]\ttrain-rmse:1.09222\tval-rmse:1.12559\ttrain-clip-rmse:0.943149\tval-clip-rmse:0.964181\n",
      "[54]\ttrain-rmse:1.09109\tval-rmse:1.12504\ttrain-clip-rmse:0.942217\tval-clip-rmse:0.963764\n",
      "[55]\ttrain-rmse:1.08996\tval-rmse:1.12418\ttrain-clip-rmse:0.941469\tval-clip-rmse:0.963214\n",
      "[56]\ttrain-rmse:1.08856\tval-rmse:1.12304\ttrain-clip-rmse:0.94062\tval-clip-rmse:0.96254\n",
      "[57]\ttrain-rmse:1.08774\tval-rmse:1.12236\ttrain-clip-rmse:0.939813\tval-clip-rmse:0.961845\n",
      "[58]\ttrain-rmse:1.08715\tval-rmse:1.12203\ttrain-clip-rmse:0.939447\tval-clip-rmse:0.961627\n",
      "[59]\ttrain-rmse:1.08555\tval-rmse:1.12076\ttrain-clip-rmse:0.938542\tval-clip-rmse:0.960949\n",
      "[60]\ttrain-rmse:1.08515\tval-rmse:1.12065\ttrain-clip-rmse:0.938254\tval-clip-rmse:0.96089\n",
      "[61]\ttrain-rmse:1.08415\tval-rmse:1.11999\ttrain-clip-rmse:0.937757\tval-clip-rmse:0.96057\n",
      "[62]\ttrain-rmse:1.08389\tval-rmse:1.11982\ttrain-clip-rmse:0.937567\tval-clip-rmse:0.960448\n",
      "[63]\ttrain-rmse:1.0827\tval-rmse:1.11904\ttrain-clip-rmse:0.936795\tval-clip-rmse:0.959916\n",
      "[64]\ttrain-rmse:1.08213\tval-rmse:1.11883\ttrain-clip-rmse:0.936477\tval-clip-rmse:0.959839\n",
      "[65]\ttrain-rmse:1.08124\tval-rmse:1.11822\ttrain-clip-rmse:0.935977\tval-clip-rmse:0.959518\n",
      "[66]\ttrain-rmse:1.08006\tval-rmse:1.1173\ttrain-clip-rmse:0.935012\tval-clip-rmse:0.958768\n",
      "[67]\ttrain-rmse:1.07949\tval-rmse:1.11686\ttrain-clip-rmse:0.93464\tval-clip-rmse:0.958594\n",
      "[68]\ttrain-rmse:1.07792\tval-rmse:1.11555\ttrain-clip-rmse:0.933293\tval-clip-rmse:0.957592\n",
      "[69]\ttrain-rmse:1.07679\tval-rmse:1.11468\ttrain-clip-rmse:0.932474\tval-clip-rmse:0.95691\n",
      "[70]\ttrain-rmse:1.07626\tval-rmse:1.11447\ttrain-clip-rmse:0.932039\tval-clip-rmse:0.956738\n",
      "[71]\ttrain-rmse:1.076\tval-rmse:1.11434\ttrain-clip-rmse:0.931809\tval-clip-rmse:0.956625\n",
      "[72]\ttrain-rmse:1.07503\tval-rmse:1.11392\ttrain-clip-rmse:0.931105\tval-clip-rmse:0.956218\n",
      "[73]\ttrain-rmse:1.07457\tval-rmse:1.1137\ttrain-clip-rmse:0.930734\tval-clip-rmse:0.95601\n",
      "[74]\ttrain-rmse:1.07372\tval-rmse:1.11304\ttrain-clip-rmse:0.930258\tval-clip-rmse:0.955643\n",
      "[75]\ttrain-rmse:1.07326\tval-rmse:1.11276\ttrain-clip-rmse:0.929859\tval-clip-rmse:0.955395\n",
      "[76]\ttrain-rmse:1.07275\tval-rmse:1.11251\ttrain-clip-rmse:0.929541\tval-clip-rmse:0.95521\n",
      "[77]\ttrain-rmse:1.07178\tval-rmse:1.11213\ttrain-clip-rmse:0.928748\tval-clip-rmse:0.954901\n",
      "[78]\ttrain-rmse:1.07105\tval-rmse:1.11153\ttrain-clip-rmse:0.928124\tval-clip-rmse:0.954335\n",
      "[79]\ttrain-rmse:1.07085\tval-rmse:1.11143\ttrain-clip-rmse:0.927981\tval-clip-rmse:0.954236\n",
      "Repeat 0, split 1, val score = 0.954, running time = 3.226 min.\n",
      "[0]\ttrain-rmse:1.39884\tval-rmse:1.39727\ttrain-clip-rmse:1.1533\tval-clip-rmse:1.1523\n",
      "[1]\ttrain-rmse:1.36698\tval-rmse:1.36637\ttrain-clip-rmse:1.1219\tval-clip-rmse:1.1217\n",
      "[2]\ttrain-rmse:1.31326\tval-rmse:1.31008\ttrain-clip-rmse:1.08588\tval-clip-rmse:1.08479\n",
      "[3]\ttrain-rmse:1.29477\tval-rmse:1.29227\ttrain-clip-rmse:1.06947\tval-clip-rmse:1.06898\n",
      "[4]\ttrain-rmse:1.2812\tval-rmse:1.27954\ttrain-clip-rmse:1.05834\tval-clip-rmse:1.05861\n",
      "[5]\ttrain-rmse:1.26898\tval-rmse:1.26723\ttrain-clip-rmse:1.05028\tval-clip-rmse:1.051\n",
      "[6]\ttrain-rmse:1.24099\tval-rmse:1.23876\ttrain-clip-rmse:1.03623\tval-clip-rmse:1.03733\n",
      "[7]\ttrain-rmse:1.23127\tval-rmse:1.23048\ttrain-clip-rmse:1.03001\tval-clip-rmse:1.03224\n",
      "[8]\ttrain-rmse:1.22646\tval-rmse:1.22578\ttrain-clip-rmse:1.02556\tval-clip-rmse:1.0279\n",
      "[9]\ttrain-rmse:1.21628\tval-rmse:1.21654\ttrain-clip-rmse:1.0179\tval-clip-rmse:1.02078\n",
      "[10]\ttrain-rmse:1.21282\tval-rmse:1.21327\ttrain-clip-rmse:1.01515\tval-clip-rmse:1.01812\n",
      "[11]\ttrain-rmse:1.21074\tval-rmse:1.21137\ttrain-clip-rmse:1.01351\tval-clip-rmse:1.01665\n",
      "[12]\ttrain-rmse:1.20835\tval-rmse:1.20947\ttrain-clip-rmse:1.01172\tval-clip-rmse:1.01517\n",
      "[13]\ttrain-rmse:1.19139\tval-rmse:1.19286\ttrain-clip-rmse:1.00572\tval-clip-rmse:1.00964\n",
      "[14]\ttrain-rmse:1.18477\tval-rmse:1.18641\ttrain-clip-rmse:1.00205\tval-clip-rmse:1.00643\n",
      "[15]\ttrain-rmse:1.17865\tval-rmse:1.18141\ttrain-clip-rmse:0.999381\tval-clip-rmse:1.00432\n",
      "[16]\ttrain-rmse:1.17808\tval-rmse:1.18094\ttrain-clip-rmse:0.998935\tval-clip-rmse:1.004\n",
      "[17]\ttrain-rmse:1.17438\tval-rmse:1.17806\ttrain-clip-rmse:0.996484\tval-clip-rmse:1.00197\n",
      "[18]\ttrain-rmse:1.17251\tval-rmse:1.17611\ttrain-clip-rmse:0.995058\tval-clip-rmse:1.00067\n",
      "[19]\ttrain-rmse:1.17131\tval-rmse:1.17532\ttrain-clip-rmse:0.994068\tval-clip-rmse:1.00004\n",
      "[20]\ttrain-rmse:1.16654\tval-rmse:1.17058\ttrain-clip-rmse:0.992374\tval-clip-rmse:0.9987\n",
      "[21]\ttrain-rmse:1.15881\tval-rmse:1.16393\ttrain-clip-rmse:0.987425\tval-clip-rmse:0.99435\n",
      "[22]\ttrain-rmse:1.15587\tval-rmse:1.16145\ttrain-clip-rmse:0.985489\tval-clip-rmse:0.992768\n",
      "[23]\ttrain-rmse:1.14978\tval-rmse:1.15638\ttrain-clip-rmse:0.9814\tval-clip-rmse:0.98944\n",
      "[24]\ttrain-rmse:1.14795\tval-rmse:1.15464\ttrain-clip-rmse:0.979953\tval-clip-rmse:0.988101\n",
      "[25]\ttrain-rmse:1.14478\tval-rmse:1.15224\ttrain-clip-rmse:0.978138\tval-clip-rmse:0.986856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\ttrain-rmse:1.14342\tval-rmse:1.1514\ttrain-clip-rmse:0.977186\tval-clip-rmse:0.986203\n",
      "[27]\ttrain-rmse:1.14168\tval-rmse:1.15005\ttrain-clip-rmse:0.97582\tval-clip-rmse:0.98517\n",
      "[28]\ttrain-rmse:1.14026\tval-rmse:1.14878\ttrain-clip-rmse:0.974828\tval-clip-rmse:0.984406\n",
      "[29]\ttrain-rmse:1.13927\tval-rmse:1.14816\ttrain-clip-rmse:0.974042\tval-clip-rmse:0.983914\n",
      "[30]\ttrain-rmse:1.13441\tval-rmse:1.14424\ttrain-clip-rmse:0.970766\tval-clip-rmse:0.981189\n",
      "[31]\ttrain-rmse:1.13146\tval-rmse:1.14184\ttrain-clip-rmse:0.96881\tval-clip-rmse:0.979569\n",
      "[32]\ttrain-rmse:1.13107\tval-rmse:1.14152\ttrain-clip-rmse:0.968406\tval-clip-rmse:0.979225\n",
      "[33]\ttrain-rmse:1.12921\tval-rmse:1.14019\ttrain-clip-rmse:0.966936\tval-clip-rmse:0.97819\n",
      "[34]\ttrain-rmse:1.12743\tval-rmse:1.13913\ttrain-clip-rmse:0.965761\tval-clip-rmse:0.977399\n",
      "[35]\ttrain-rmse:1.12698\tval-rmse:1.13893\ttrain-clip-rmse:0.965418\tval-clip-rmse:0.977283\n",
      "[36]\ttrain-rmse:1.12282\tval-rmse:1.13542\ttrain-clip-rmse:0.96257\tval-clip-rmse:0.974879\n",
      "[37]\ttrain-rmse:1.12157\tval-rmse:1.13469\ttrain-clip-rmse:0.961513\tval-clip-rmse:0.974168\n",
      "[38]\ttrain-rmse:1.12086\tval-rmse:1.1342\ttrain-clip-rmse:0.961106\tval-clip-rmse:0.973839\n",
      "[39]\ttrain-rmse:1.11978\tval-rmse:1.13322\ttrain-clip-rmse:0.960483\tval-clip-rmse:0.973222\n",
      "[40]\ttrain-rmse:1.11786\tval-rmse:1.13137\ttrain-clip-rmse:0.958947\tval-clip-rmse:0.971783\n",
      "[41]\ttrain-rmse:1.11486\tval-rmse:1.12782\ttrain-clip-rmse:0.956957\tval-clip-rmse:0.969562\n",
      "[42]\ttrain-rmse:1.11358\tval-rmse:1.12675\ttrain-clip-rmse:0.955935\tval-clip-rmse:0.968682\n",
      "[43]\ttrain-rmse:1.11206\tval-rmse:1.12562\ttrain-clip-rmse:0.954949\tval-clip-rmse:0.967945\n",
      "[44]\ttrain-rmse:1.11072\tval-rmse:1.12454\ttrain-clip-rmse:0.954082\tval-clip-rmse:0.967308\n",
      "[45]\ttrain-rmse:1.10997\tval-rmse:1.124\ttrain-clip-rmse:0.953651\tval-clip-rmse:0.967016\n",
      "[46]\ttrain-rmse:1.10716\tval-rmse:1.12131\ttrain-clip-rmse:0.952103\tval-clip-rmse:0.965712\n",
      "[47]\ttrain-rmse:1.10622\tval-rmse:1.12061\ttrain-clip-rmse:0.951325\tval-clip-rmse:0.965166\n",
      "[48]\ttrain-rmse:1.10577\tval-rmse:1.12028\ttrain-clip-rmse:0.950929\tval-clip-rmse:0.964896\n",
      "[49]\ttrain-rmse:1.10568\tval-rmse:1.12023\ttrain-clip-rmse:0.950864\tval-clip-rmse:0.96485\n",
      "[50]\ttrain-rmse:1.10083\tval-rmse:1.11685\ttrain-clip-rmse:0.948282\tval-clip-rmse:0.963009\n",
      "[51]\ttrain-rmse:1.09898\tval-rmse:1.11563\ttrain-clip-rmse:0.947026\tval-clip-rmse:0.962101\n",
      "[52]\ttrain-rmse:1.09868\tval-rmse:1.11557\ttrain-clip-rmse:0.946842\tval-clip-rmse:0.962117\n",
      "[53]\ttrain-rmse:1.09801\tval-rmse:1.11522\ttrain-clip-rmse:0.946269\tval-clip-rmse:0.961869\n",
      "[54]\ttrain-rmse:1.09681\tval-rmse:1.11436\ttrain-clip-rmse:0.945187\tval-clip-rmse:0.961041\n",
      "[55]\ttrain-rmse:1.09632\tval-rmse:1.11413\ttrain-clip-rmse:0.944778\tval-clip-rmse:0.960839\n",
      "[56]\ttrain-rmse:1.09449\tval-rmse:1.1128\ttrain-clip-rmse:0.943857\tval-clip-rmse:0.959897\n",
      "[57]\ttrain-rmse:1.09407\tval-rmse:1.11257\ttrain-clip-rmse:0.943481\tval-clip-rmse:0.95963\n",
      "[58]\ttrain-rmse:1.0928\tval-rmse:1.11175\ttrain-clip-rmse:0.942821\tval-clip-rmse:0.95922\n",
      "[59]\ttrain-rmse:1.09208\tval-rmse:1.11146\ttrain-clip-rmse:0.942369\tval-clip-rmse:0.959059\n",
      "[60]\ttrain-rmse:1.09085\tval-rmse:1.11031\ttrain-clip-rmse:0.941581\tval-clip-rmse:0.958352\n",
      "[61]\ttrain-rmse:1.09027\tval-rmse:1.10988\ttrain-clip-rmse:0.941106\tval-clip-rmse:0.95804\n",
      "[62]\ttrain-rmse:1.08936\tval-rmse:1.10909\ttrain-clip-rmse:0.94027\tval-clip-rmse:0.957376\n",
      "[63]\ttrain-rmse:1.08742\tval-rmse:1.10758\ttrain-clip-rmse:0.938777\tval-clip-rmse:0.956158\n",
      "[64]\ttrain-rmse:1.08627\tval-rmse:1.10672\ttrain-clip-rmse:0.937918\tval-clip-rmse:0.95549\n",
      "[65]\ttrain-rmse:1.08589\tval-rmse:1.10673\ttrain-clip-rmse:0.937603\tval-clip-rmse:0.955491\n",
      "[66]\ttrain-rmse:1.08255\tval-rmse:1.10385\ttrain-clip-rmse:0.935119\tval-clip-rmse:0.953282\n",
      "[67]\ttrain-rmse:1.082\tval-rmse:1.10373\ttrain-clip-rmse:0.934695\tval-clip-rmse:0.953222\n",
      "[68]\ttrain-rmse:1.08037\tval-rmse:1.10252\ttrain-clip-rmse:0.933602\tval-clip-rmse:0.952462\n",
      "[69]\ttrain-rmse:1.0779\tval-rmse:1.10047\ttrain-clip-rmse:0.931501\tval-clip-rmse:0.9507\n",
      "[70]\ttrain-rmse:1.07665\tval-rmse:1.09946\ttrain-clip-rmse:0.930512\tval-clip-rmse:0.949933\n",
      "[71]\ttrain-rmse:1.07534\tval-rmse:1.09857\ttrain-clip-rmse:0.929743\tval-clip-rmse:0.949459\n",
      "[72]\ttrain-rmse:1.07514\tval-rmse:1.09856\ttrain-clip-rmse:0.929574\tval-clip-rmse:0.949417\n",
      "[73]\ttrain-rmse:1.07343\tval-rmse:1.09742\ttrain-clip-rmse:0.928781\tval-clip-rmse:0.948865\n",
      "[74]\ttrain-rmse:1.07176\tval-rmse:1.09605\ttrain-clip-rmse:0.927793\tval-clip-rmse:0.948067\n",
      "[75]\ttrain-rmse:1.07137\tval-rmse:1.09601\ttrain-clip-rmse:0.927435\tval-clip-rmse:0.948023\n",
      "[76]\ttrain-rmse:1.07051\tval-rmse:1.09529\ttrain-clip-rmse:0.926596\tval-clip-rmse:0.947319\n",
      "[77]\ttrain-rmse:1.06965\tval-rmse:1.09465\ttrain-clip-rmse:0.925898\tval-clip-rmse:0.946801\n",
      "[78]\ttrain-rmse:1.06906\tval-rmse:1.09423\ttrain-clip-rmse:0.925341\tval-clip-rmse:0.946408\n",
      "[79]\ttrain-rmse:1.06834\tval-rmse:1.09376\ttrain-clip-rmse:0.924765\tval-clip-rmse:0.945995\n",
      "Repeat 0, split 2, val score = 0.946, running time = 3.272 min.\n",
      "Val mean = 0.951, std = 0.004\n"
     ]
    }
   ],
   "source": [
    "param = {'max_depth':8, \n",
    "         'subsample':0.8,\n",
    "         'min_child_weight':10,\n",
    "         'eta':0.3, \n",
    "         'lambda':2,\n",
    "         'colsample_bytree':0.8,\n",
    "         'seed':1,\n",
    "         'silent':1,\n",
    "         'maximize': False,\n",
    "         'nthread':8}\n",
    "\n",
    "n_tree = 80\n",
    "verbose = True\n",
    "\n",
    "n_split = 3\n",
    "n_repetition = 1\n",
    "\n",
    "df, clf, running_time = cv(x_train, y_train, param, n_repetition, n_split, n_tree, verbose, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {k: clf[k].get_score(importance_type='gain') for k in clf.keys()}\n",
    "\n",
    "b = pd.DataFrame(a)\n",
    "\n",
    "b.columns = list(range(n_split))\n",
    "\n",
    "c = b.mean(axis=1).sort_values(ascending=False)\n",
    "\n",
    "d = c.head(50).index.tolist()\n",
    "e = []\n",
    "f = []\n",
    "for n in d:\n",
    "    if len(n.split('_'))>=2 and n.split('_')[-2] == 'lag':\n",
    "        e.append('_'.join(n.split('_')[:-2]))\n",
    "        f.append(int(n.split('_')[-1]))\n",
    "        \n",
    "e = set(e)\n",
    "f = set(f)\n",
    "\n",
    "b.to_csv('eda_11_6_feature_importance.csv')\n",
    "\n",
    "plt.plot(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.39526\ttrain-clip-rmse:1.15019\n",
      "[1]\ttrain-rmse:1.3532\ttrain-clip-rmse:1.11629\n",
      "[2]\ttrain-rmse:1.3008\ttrain-clip-rmse:1.08073\n",
      "[3]\ttrain-rmse:1.27842\ttrain-clip-rmse:1.06496\n",
      "[4]\ttrain-rmse:1.26531\ttrain-clip-rmse:1.05443\n",
      "[5]\ttrain-rmse:1.25408\ttrain-clip-rmse:1.04566\n",
      "[6]\ttrain-rmse:1.24439\ttrain-clip-rmse:1.03735\n",
      "[7]\ttrain-rmse:1.22739\ttrain-clip-rmse:1.03086\n",
      "[8]\ttrain-rmse:1.21845\ttrain-clip-rmse:1.0252\n",
      "[9]\ttrain-rmse:1.21219\ttrain-clip-rmse:1.01997\n",
      "[10]\ttrain-rmse:1.20154\ttrain-clip-rmse:1.01223\n",
      "[11]\ttrain-rmse:1.1982\ttrain-clip-rmse:1.01001\n",
      "[12]\ttrain-rmse:1.18693\ttrain-clip-rmse:1.00573\n",
      "[13]\ttrain-rmse:1.18256\ttrain-clip-rmse:1.00212\n",
      "[14]\ttrain-rmse:1.17883\ttrain-clip-rmse:0.999844\n",
      "[15]\ttrain-rmse:1.17628\ttrain-clip-rmse:0.997886\n",
      "[16]\ttrain-rmse:1.17062\ttrain-clip-rmse:0.995967\n",
      "[17]\ttrain-rmse:1.16702\ttrain-clip-rmse:0.993079\n",
      "[18]\ttrain-rmse:1.16575\ttrain-clip-rmse:0.992028\n",
      "[19]\ttrain-rmse:1.16403\ttrain-clip-rmse:0.990713\n",
      "[20]\ttrain-rmse:1.15864\ttrain-clip-rmse:0.987476\n",
      "[21]\ttrain-rmse:1.15739\ttrain-clip-rmse:0.986439\n",
      "[22]\ttrain-rmse:1.15268\ttrain-clip-rmse:0.982722\n",
      "[23]\ttrain-rmse:1.14722\ttrain-clip-rmse:0.980195\n",
      "[24]\ttrain-rmse:1.14546\ttrain-clip-rmse:0.978908\n",
      "[25]\ttrain-rmse:1.14165\ttrain-clip-rmse:0.976443\n",
      "[26]\ttrain-rmse:1.14064\ttrain-clip-rmse:0.975525\n",
      "[27]\ttrain-rmse:1.13935\ttrain-clip-rmse:0.974555\n",
      "[28]\ttrain-rmse:1.13802\ttrain-clip-rmse:0.973519\n",
      "[29]\ttrain-rmse:1.13497\ttrain-clip-rmse:0.971469\n",
      "[30]\ttrain-rmse:1.13314\ttrain-clip-rmse:0.970015\n",
      "[31]\ttrain-rmse:1.13088\ttrain-clip-rmse:0.968756\n",
      "[32]\ttrain-rmse:1.12862\ttrain-clip-rmse:0.966748\n",
      "[33]\ttrain-rmse:1.12836\ttrain-clip-rmse:0.966519\n",
      "[34]\ttrain-rmse:1.12651\ttrain-clip-rmse:0.965396\n",
      "[35]\ttrain-rmse:1.1247\ttrain-clip-rmse:0.964029\n",
      "[36]\ttrain-rmse:1.12411\ttrain-clip-rmse:0.963558\n",
      "[37]\ttrain-rmse:1.12052\ttrain-clip-rmse:0.961977\n",
      "[38]\ttrain-rmse:1.11772\ttrain-clip-rmse:0.959739\n",
      "[39]\ttrain-rmse:1.11609\ttrain-clip-rmse:0.958779\n",
      "[40]\ttrain-rmse:1.11351\ttrain-clip-rmse:0.957278\n",
      "[41]\ttrain-rmse:1.11273\ttrain-clip-rmse:0.956721\n",
      "[42]\ttrain-rmse:1.11177\ttrain-clip-rmse:0.9559\n",
      "[43]\ttrain-rmse:1.11116\ttrain-clip-rmse:0.955592\n",
      "[44]\ttrain-rmse:1.11037\ttrain-clip-rmse:0.954869\n",
      "[45]\ttrain-rmse:1.11006\ttrain-clip-rmse:0.954665\n",
      "[46]\ttrain-rmse:1.1091\ttrain-clip-rmse:0.954022\n",
      "[47]\ttrain-rmse:1.10655\ttrain-clip-rmse:0.95227\n",
      "[48]\ttrain-rmse:1.10477\ttrain-clip-rmse:0.950894\n",
      "[49]\ttrain-rmse:1.10148\ttrain-clip-rmse:0.949113\n",
      "[50]\ttrain-rmse:1.10038\ttrain-clip-rmse:0.948294\n",
      "[51]\ttrain-rmse:1.09855\ttrain-clip-rmse:0.947161\n",
      "[52]\ttrain-rmse:1.09801\ttrain-clip-rmse:0.94681\n",
      "[53]\ttrain-rmse:1.09752\ttrain-clip-rmse:0.946376\n",
      "[54]\ttrain-rmse:1.0968\ttrain-clip-rmse:0.945984\n",
      "[55]\ttrain-rmse:1.09102\ttrain-clip-rmse:0.942912\n",
      "[56]\ttrain-rmse:1.09029\ttrain-clip-rmse:0.942382\n",
      "[57]\ttrain-rmse:1.08929\ttrain-clip-rmse:0.941772\n",
      "[58]\ttrain-rmse:1.0883\ttrain-clip-rmse:0.940981\n",
      "[59]\ttrain-rmse:1.08726\ttrain-clip-rmse:0.940095\n",
      "[60]\ttrain-rmse:1.08603\ttrain-clip-rmse:0.939349\n",
      "[61]\ttrain-rmse:1.08542\ttrain-clip-rmse:0.938774\n",
      "[62]\ttrain-rmse:1.085\ttrain-clip-rmse:0.938441\n",
      "[63]\ttrain-rmse:1.08357\ttrain-clip-rmse:0.937517\n",
      "[64]\ttrain-rmse:1.08299\ttrain-clip-rmse:0.937103\n",
      "[65]\ttrain-rmse:1.08198\ttrain-clip-rmse:0.936453\n",
      "[66]\ttrain-rmse:1.0819\ttrain-clip-rmse:0.936402\n",
      "[67]\ttrain-rmse:1.08174\ttrain-clip-rmse:0.936252\n",
      "[68]\ttrain-rmse:1.0811\ttrain-clip-rmse:0.93564\n",
      "[69]\ttrain-rmse:1.07997\ttrain-clip-rmse:0.934916\n",
      "[70]\ttrain-rmse:1.0795\ttrain-clip-rmse:0.93446\n",
      "[71]\ttrain-rmse:1.07867\ttrain-clip-rmse:0.933811\n",
      "[72]\ttrain-rmse:1.07854\ttrain-clip-rmse:0.933687\n",
      "[73]\ttrain-rmse:1.07779\ttrain-clip-rmse:0.933104\n",
      "[74]\ttrain-rmse:1.07715\ttrain-clip-rmse:0.932622\n",
      "[75]\ttrain-rmse:1.07628\ttrain-clip-rmse:0.931964\n",
      "[76]\ttrain-rmse:1.07532\ttrain-clip-rmse:0.931174\n",
      "[77]\ttrain-rmse:1.07491\ttrain-clip-rmse:0.930862\n",
      "[78]\ttrain-rmse:1.0747\ttrain-clip-rmse:0.930705\n",
      "[79]\ttrain-rmse:1.07417\ttrain-clip-rmse:0.93026\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "bst = xgb.train(param, dtrain, num_boost_round=n_tree, \n",
    "                evals=[(dtrain, 'train')], feval=clip_rmse, maximize=False, \n",
    "                verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bst.predict(xgb.DMatrix(x_test))\n",
    "preds = list(map(lambda x: min(20, max(x, 0)), list(preds)))\n",
    "sub_df = pd.DataFrame({'ID': test.index, 'item_cnt_month': preds})\n",
    "sub_df.to_csv('eda_11_6.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
