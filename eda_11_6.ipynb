{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import gc\n",
    "import itertools\n",
    "import tqdm\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import scipy.stats as ss\n",
    "from numba import jit\n",
    "\n",
    "if os.name=='nt':\n",
    "    try:\n",
    "        mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin'\n",
    "        os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_features(df, lags, merge_cols, shift_cols, fillna_value=None):\n",
    "    '''create lag features of col'''\n",
    "    cols = copy.copy(merge_cols)\n",
    "    cols.extend(shift_cols)\n",
    "    tmp = df.loc[:, cols]\n",
    "    for i in lags:\n",
    "        shifted = tmp.copy()\n",
    "        shifted_cols = shifted.columns.tolist()\n",
    "        shifted_cols = [c+'_lag_'+str(i) if c in shift_cols else c \n",
    "                        for c in shifted_cols]\n",
    "        shifted.columns = shifted_cols\n",
    "        shifted[merge_cols] += i\n",
    "        shifted.drop_duplicates(inplace=True)\n",
    "        df = pd.merge(df, shifted, on=merge_cols, how='left')\n",
    "    if fillna_value is not None:\n",
    "        df.fillna(fillna_value, inplace=True)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_rmse(preds, dtrain):\n",
    "    y_test = np.array(dtrain.get_label())\n",
    "    preds = np.array(preds)\n",
    "    y_test = np.maximum(np.minimum(y_test, 20), 0)\n",
    "    preds = np.maximum(np.minimum(preds, 20), 0)\n",
    "    #preds = np.array(list(map(lambda x: min(20, max(x, 0)), list(preds))))\n",
    "    #y_test = np.array(list(map(lambda x: min(20, max(x, 0)), list(y_test))))\n",
    "    rmse = np.sqrt(mean_squared_error(preds,y_test))\n",
    "    return 'clip-rmse', rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(x_train, y_train, param, n_repetition, n_split, n_tree, verbose, random_state):\n",
    "    '''Repeated CV'''\n",
    "    \n",
    "    cv_results = {}\n",
    "    clf = {}\n",
    "    running_time = {}\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    for m in range(n_repetition):\n",
    "        # Train and valuation sets split\n",
    "        skf = StratifiedKFold(n_splits=n_split, random_state=np.random.randint(10**6), shuffle=True)\n",
    "\n",
    "        for n, (train_index, val_index) in enumerate(skf.split(x_train, y_train)):\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Construct DMatrix\n",
    "            dtrain = xgb.DMatrix(x_train.iloc[train_index], label=y_train.iloc[train_index])\n",
    "            dval = xgb.DMatrix(x_train.iloc[val_index], label=y_train.iloc[val_index])\n",
    "\n",
    "            # Placeholder for evals_results\n",
    "            cv_results[m, n] = {}\n",
    "\n",
    "            param['seed'] = np.random.randint(10**6)\n",
    "            clf[m, n] = xgb.train(param, dtrain,num_boost_round=n_tree, \n",
    "                                  evals=[(dtrain, 'train'), (dval, 'val')], \n",
    "                                  feval=clip_rmse, maximize=False, early_stopping_rounds=None, \n",
    "                                  evals_result=cv_results[m, n], verbose_eval=verbose)\n",
    "\n",
    "            running_time[m, n] = time.time() - start_time\n",
    "\n",
    "            print('Repeat {}, split {}, val score = {:.3f}, running time = {:.3f} min.'.format(m, n, \n",
    "                cv_results[m, n]['val']['clip-rmse'][-1], running_time[m, n]/60))\n",
    "\n",
    "    cv_results_final = {}\n",
    "    for m in range(n_repetition):\n",
    "        for n in range(n_split):\n",
    "            cv_results_final['train', m, n] = cv_results[m, n]['train']['clip-rmse']\n",
    "            cv_results_final['val', m, n] = cv_results[m, n]['val']['clip-rmse']\n",
    "\n",
    "    df = pd.DataFrame(cv_results_final)\n",
    "    df.index.name = 'iteration'\n",
    "    df.columns.names = ['dataset', 'repetition', 'cv_split']\n",
    "\n",
    "    print('Val mean = {:.3f}, std = {:.3f}'.format(df['val'].iloc[-1].mean(), df['val'].iloc[-1].std()))\n",
    "    \n",
    "    return df, clf, running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_combination(x, feature_list, function_dict, column_name, merge=False):\n",
    "    '''Combination of new features'''\n",
    "    tmp = x.groupby(feature_list).agg(function_dict)\n",
    "    tmp.columns = column_name\n",
    "    if merge:\n",
    "        x = x.merge(tmp, on=feature_list, how='left')\n",
    "        return x, tmp\n",
    "    else:\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('all/sales_train.csv.gz')\n",
    "test = pd.read_csv('all/test.csv.gz')\n",
    "shop = pd.read_csv('all/shops-translated.csv')\n",
    "item = pd.read_csv('all/item_category.csv')\n",
    "\n",
    "test.set_index('ID', inplace=True)\n",
    "item.drop(['item_name_translated'], axis=1, inplace=True)\n",
    "shop.drop(['Name'], axis=1, inplace=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "item['item_cat1'] = le.fit_transform(item['item_cat1'].astype(str))\n",
    "item['item_cat2'] = le.fit_transform(item['item_cat2'].astype(str))\n",
    "shop['City'] = le.fit_transform(shop['City'])\n",
    "shop['Type'] = le.fit_transform(shop['Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.item_price<100000]\n",
    "train = train[train.item_cnt_day<1001]\n",
    "median = train[(train.shop_id==32)&(train.item_id==2973)&(train.date_block_num==4)&(train.item_price>0)].item_price.median()\n",
    "train.loc[train.item_price<0, 'item_price'] = median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix shop names and ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "train.loc[train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monthly sales for all the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(train.groupby(['date_block_num', 'shop_id', 'item_id'])['item_cnt_day'].sum())\n",
    "\n",
    "x.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set only contains sold samples, need to extend to all samples.\n",
    "\n",
    "There are two ways of extending:\n",
    "1. overall product between elements in (month, shop_id, item_id)\n",
    "2. in each month, the product between elements in (shop_id, item_id)\n",
    "\n",
    "The first one increases the number of rows by 23.5 times, the second one 6 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall product count is 42260028, sample count is 1609123, ratio is 26.263\n",
      "monthly product count sum is 10913804, monthly sample count is 1609123, ratio is 6.782\n"
     ]
    }
   ],
   "source": [
    "shop_count = {}\n",
    "item_count = {}\n",
    "product_count = {}\n",
    "sample_count = {}\n",
    "ratio = {}\n",
    "\n",
    "for n in x.date_block_num.unique():\n",
    "    shop_count[n] = len(x.loc[x.date_block_num==n, 'shop_id'].unique())\n",
    "    item_count[n] = len(x.loc[x.date_block_num==n, 'item_id'].unique())\n",
    "    sample_count[n] = len(x.loc[x.date_block_num==n, :])\n",
    "    product_count[n] = shop_count[n]*item_count[n]\n",
    "    ratio[n] = product_count[n]/sample_count[n]\n",
    "#     print('product count is {}, sample count is {}, ratio is {:.3f}'.format(product_count[n], \n",
    "#                                                                             sample_count[n], \n",
    "#                                                                             product_count[n]/sample_count[n]))\n",
    "    \n",
    "print('overall product count is {}, sample count is {}, ratio is {:.3f}'.format(\n",
    "    len(x.shop_id.unique())*len(x.item_id.unique())*34, \n",
    "    x.shape[0], 34*len(x.shop_id.unique())*len(x.item_id.unique())/x.shape[0]))\n",
    "print('monthly product count sum is {}, monthly sample count is {}, ratio is {:.3f}'.format(\n",
    "    sum(product_count.values()), sum(sample_count.values()), sum(product_count.values())/sum(sample_count.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the first extending method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = np.arange(0, 34)\n",
    "shop_list = train.shop_id.unique().tolist()\n",
    "item_list = train.item_id.unique().tolist()\n",
    "n_rows = len(month)*len(shop_list)*len(item_list)\n",
    "\n",
    "idx = pd.MultiIndex.from_product([month, shop_list, item_list], names=['date_block_num', 'shop_id', 'item_id'])\n",
    "\n",
    "x2 = pd.DataFrame(np.zeros((n_rows,2)), index=idx)\n",
    "x2.reset_index(inplace=True, drop=False)\n",
    "x2.drop([0, 1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x2.merge(x, on=['date_block_num', 'shop_id', 'item_id'], how='outer').fillna(0.0)\n",
    "test['date_block_num'] = 34\n",
    "x = pd.concat((x, test), sort=False).fillna(0.0)\n",
    "\n",
    "del x2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add shop/item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.merge(x, shop, on='shop_id', how='left')\n",
    "x = pd.merge(x, item, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>City</th>\n",
       "      <th>Type</th>\n",
       "      <th>item_cat1</th>\n",
       "      <th>item_cat2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id  item_cnt_day  City  Type  item_cat1  \\\n",
       "0               0       59    22154           1.0    27     1          3   \n",
       "1               0       59     2552           0.0    27     1         12   \n",
       "2               0       59     2554           0.0    27     1         12   \n",
       "3               0       59     2555           0.0    27     1         12   \n",
       "4               0       59     2564           0.0    27     1         12   \n",
       "\n",
       "   item_cat2  \n",
       "0          9  \n",
       "1         56  \n",
       "2         56  \n",
       "3         15  \n",
       "4         38  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns = ['month', 'shop_id', 'item_id', 'sales_month', \n",
    "             'City', 'Type', 'item_cat1', 'item_cat2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['City'] = x['City'].astype(np.int8)\n",
    "x['Type'] = x['Type'].astype(np.int8)\n",
    "x['item_cat1'] = x['item_cat1'].astype(np.int8)\n",
    "x['item_cat2'] = x['item_cat2'].astype(np.int8)\n",
    "x['sales_month'] = x['sales_month'].astype(np.float16)\n",
    "x['month'] = x['month'].astype(np.int8)\n",
    "x['shop_id'] = x['shop_id'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lag_features(x, [1, 2, 3, 6, 12], \n",
    "                 ['month', 'shop_id', 'item_id'], \n",
    "                 ['sales_month'], fillna_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = x.groupby('month').agg({'sales_month': ['mean']})\n",
    "group.columns = ['sales_mean_month']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=['month'], how='left')\n",
    "x['sales_mean_month'] = x['sales_mean_month'].astype(np.float16)\n",
    "x = lag_features(x, [1], ['month'], ['sales_mean_month'], fillna_value=0.0)\n",
    "x.drop(['sales_mean_month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_item`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_item'\n",
    "group = x.groupby(['month', 'item_id']).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=['month', 'item_id'], how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1, 2, 3, 6, 12], \n",
    "                 ['month', 'item_id'], \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_shop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_shop'\n",
    "merge_cols = ['month', 'shop_id']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1, 2, 3, 6, 12], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_cat1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_cat1'\n",
    "merge_cols = ['month', 'item_cat1']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_shop_cat1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_shop_cat1'\n",
    "merge_cols = ['month', 'shop_id', 'item_cat1']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_shop_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_shop_type'\n",
    "merge_cols = ['month', 'shop_id', 'Type']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_shop_cat2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_shop_cat2'\n",
    "merge_cols = ['month', 'shop_id', 'item_cat2']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_city`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_city'\n",
    "merge_cols = ['month', 'City']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_item_city`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_item_city'\n",
    "merge_cols = ['month', 'item_id', 'City']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_cat2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_cat2'\n",
    "merge_cols = ['month', 'item_cat2']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sales_mean_month_cat1_cat2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_mean_month_cat1_cat2'\n",
    "merge_cols = ['month', 'item_cat1', 'item_cat2']\n",
    "group = x.groupby(merge_cols).agg({'sales_month': ['mean']})\n",
    "group.columns = [col]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "x = pd.merge(x, group, on=merge_cols, how='left')\n",
    "x[col] = x[col].astype(np.float16)\n",
    "x = lag_features(x, [1, 2, 3, 6], \n",
    "                 merge_cols, \n",
    "                 [col], fillna_value=0.0)\n",
    "x.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "x.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = x.sample(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test sets\n",
    "x_train = x.loc[(x['month']<=33) & (x['month']>=12), :].copy()\n",
    "x_test = x.loc[x['month']==34, :].copy()\n",
    "\n",
    "# Drop target from test set\n",
    "x_test.drop(['month'], axis=1, inplace=True)\n",
    "\n",
    "# Split target from train set\n",
    "# Note that target is first clipped to (0, 40), then clipped to (0, 20) in test set. \n",
    "# This is similar to the idea of calibration\n",
    "y_train = x_train['sales_month'].clip(0, 20)\n",
    "x_train.drop(['sales_month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-940277af5fc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mn_repetition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_repetition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-0c6e987cd55f>\u001b[0m in \u001b[0;36mcv\u001b[1;34m(x_train, y_train, param, n_repetition, n_split, n_tree, verbose, random_state)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;31m# Construct DMatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mdtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mdval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\xgboost-0.72-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[0;32m    266\u001b[0m         data, feature_names, feature_types = _maybe_pandas_data(data,\n\u001b[0;32m    267\u001b[0m                                                                 \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m                                                                 feature_types)\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_pandas_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\xgboost-0.72-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[1;34m(data, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mfeature_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mPANDAS_DTYPE_MAPPER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_dtypes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4631\u001b[0m         \"\"\"\n\u001b[0;32m   4632\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4633\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4635\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mas_array\u001b[1;34m(self, transpose, items)\u001b[0m\n\u001b[0;32m   3947\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3948\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3949\u001b[1;33m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3951\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtranspose\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_interleave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3958\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_interleaved_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3960\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3962\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param = {'max_depth':8, \n",
    "         'subsample':0.8,\n",
    "         'min_child_weight':300,\n",
    "         'eta':0.3, \n",
    "         'lambda':2,\n",
    "         'colsample_bytree':0.8,\n",
    "         'seed':1,\n",
    "         'silent':1,\n",
    "         'maximize': False,\n",
    "         'nthread':8}\n",
    "\n",
    "n_tree = 80\n",
    "verbose = True\n",
    "\n",
    "n_split = 3\n",
    "n_repetition = 1\n",
    "\n",
    "df, clf, running_time = cv(x_train, y_train, param, n_repetition, n_split, n_tree, verbose, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {k: clf[0, 0].get_score(importance_type='gain') for k in clf.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.columns = list(range(n_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b.mean(axis=1).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = c.head(50).index.tolist()\n",
    "e = []\n",
    "f = []\n",
    "for n in d:\n",
    "    if len(n.split('_'))>=2 and n.split('_')[-2] == 'lag':\n",
    "        e.append('_'.join(n.split('_')[:-2]))\n",
    "        f.append(int(n.split('_')[-1]))\n",
    "        \n",
    "e = set(e)\n",
    "f = set(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cnt_mean_cat1_cat2',\n",
       " 'cnt_mean_cat1_shop',\n",
       " 'cnt_mean_cat1_type',\n",
       " 'cnt_mean_cat2_type',\n",
       " 'cnt_mean_item_city',\n",
       " 'cnt_sum_month',\n",
       " 'price_mean_cat1_cat2',\n",
       " 'price_mean_cat1_type',\n",
       " 'price_mean_item_city',\n",
       " 'price_mean_month',\n",
       " 'rev_mean_cat1_cat2',\n",
       " 'rev_mean_cat1_city',\n",
       " 'rev_mean_cat1_type',\n",
       " 'rev_mean_cat2_type',\n",
       " 'rev_mean_item_city',\n",
       " 'rev_mean_item_type',\n",
       " 'rev_sum_month',\n",
       " 'shop_count_cat1_cat2'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "26*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.to_csv('eda_11_5_feature_importance.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
